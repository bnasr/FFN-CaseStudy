{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FFN Case Study.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vy1wm1mtaMwB",
        "Ni7nmZoAp8G_",
        "ERVTLJd5x7lS",
        "sByCN3q_8Ssy"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcxUvTVOqSGb"
      },
      "source": [
        "# DS Growth Case Study\n",
        "\n",
        "## Context: \n",
        "A user is looking for loans on Google and enters a search query. Depending on how related the search query is to FFN business, we choose to bid for the query with the goal of maximizing the user impressions using Google Adwords (Google actually showing the ad to the user when they execute the search). This would lead to more clicks on ads, and potentially more signups, activations, and revenue. Here activation is defined as a user successfully contacted by FFN call center.\n",
        "\n",
        "## Questions:\n",
        "\n",
        "1.\tUsing the dataset attached ‘clicks-activation_v2.csv’, build a model to predict the probability of activation per click.\n",
        "\n",
        "2.\tPlease create a presentation using the following guidelines:\n",
        "  -\tDescribe the workflow steps (explicitly setting up the optimization problem and choice of objective function) and your hypothesis.\n",
        "  -\tEvaluate the performance of the model (pre-production)?\n",
        "  -\tWhat are some of the shortcomings of this approach?\n",
        "  -\tWhat are some other features you might need to come up with a better model?\n",
        "\n",
        "3.\tWhat does the engineering architecture to productionize one of the solutions looks like? What trade-offs would you use to productionize promising algorithms faster?\n",
        "\n",
        "4.\tDiscuss how will you analyze the business performance of the algorithm once in production using metrics such as marketing ROI etc.?\n",
        "\n",
        "Each of the four parts above carry equal weightage in evaluation. We don’t think you need to spend more than 3 hours on the overall exercise (please feel free to take more time if you want). If you have questions please contact: azajic@freedomfinancialnetwork.com\n",
        "\n",
        "## Data Dictionary:\n",
        "\n",
        "1.\tcreated_date - date on which the click was recorded\n",
        "2.\tlocation_in_query - city name that appeared in search query\n",
        "3.\tplatform - platform such as web/mobile\n",
        "4.\tcampaign_state - US state where the ad campaign was run\n",
        "5.\tin_city - whether the ad campaign was run in a city or not\n",
        "6.\tis_prime - whether the word fico prime appeared in the search query\n",
        "7.\tis_hardship - whether the word hardship appeared in the search query\n",
        "8.\tcategory_debt_type - type of debt solution that appeared in the search query\n",
        "9.\t[TARGET] is_activated – whether the user talked to FFN call center or not\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBdIQmAmxDc3"
      },
      "source": [
        "import datetime\n",
        "start_time = datetime.datetime.now()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy1wm1mtaMwB"
      },
      "source": [
        "# Loading required modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Bikq0nVhQG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni7nmZoAp8G_"
      },
      "source": [
        "# Loading the data\n",
        "Let's load the data file as Pandas DateFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4ohKgfSVl91",
        "outputId": "efe469c0-13a3-4583-acab-a2ea9d1c3cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#loading the data\n",
        "clicks = pd.read_csv('drive/My Drive/ffn/data/clicks-activation_v2.csv')\n",
        "\n",
        "#creating a new column for time as integer\n",
        "clicks['time_index'] = pd.to_datetime(clicks['created_date']).astype(int)\n",
        "\n",
        "#printing data types for each columns\n",
        "print(clicks.dtypes, '\\n')\n",
        "\n",
        "#printing info summary\n",
        "print(clicks.info(), '\\n')\n",
        "\n",
        "#printing first few rows\n",
        "clicks.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created_date          object\n",
            "location_in_query     object\n",
            "platform              object\n",
            "campaign_state        object\n",
            "in_city                int64\n",
            "is_prime               int64\n",
            "is_hardship            int64\n",
            "is_activated            bool\n",
            "category_debt_type    object\n",
            "time_index             int64\n",
            "dtype: object \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 94194 entries, 0 to 94193\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   created_date        94194 non-null  object\n",
            " 1   location_in_query   94179 non-null  object\n",
            " 2   platform            94194 non-null  object\n",
            " 3   campaign_state      94188 non-null  object\n",
            " 4   in_city             94194 non-null  int64 \n",
            " 5   is_prime            94194 non-null  int64 \n",
            " 6   is_hardship         94194 non-null  int64 \n",
            " 7   is_activated        94194 non-null  bool  \n",
            " 8   category_debt_type  84335 non-null  object\n",
            " 9   time_index          94194 non-null  int64 \n",
            "dtypes: bool(1), int64(4), object(5)\n",
            "memory usage: 6.6+ MB\n",
            "None \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_date</th>\n",
              "      <th>location_in_query</th>\n",
              "      <th>platform</th>\n",
              "      <th>campaign_state</th>\n",
              "      <th>in_city</th>\n",
              "      <th>is_prime</th>\n",
              "      <th>is_hardship</th>\n",
              "      <th>is_activated</th>\n",
              "      <th>category_debt_type</th>\n",
              "      <th>time_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12/27/2017</td>\n",
              "      <td>san antonio</td>\n",
              "      <td>mobile web</td>\n",
              "      <td>tx</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>debt_settlement</td>\n",
              "      <td>1514332800000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/10/2018</td>\n",
              "      <td>honolulu</td>\n",
              "      <td>mobile web</td>\n",
              "      <td>hi</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>debt_settlement</td>\n",
              "      <td>1515542400000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12/15/2017</td>\n",
              "      <td>atlanta</td>\n",
              "      <td>desktop web</td>\n",
              "      <td>ga</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>debt_settlement</td>\n",
              "      <td>1513296000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/6/2018</td>\n",
              "      <td>honolulu</td>\n",
              "      <td>mobile web</td>\n",
              "      <td>hi</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>debt_settlement</td>\n",
              "      <td>1515196800000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12/20/2017</td>\n",
              "      <td>South Beachmi</td>\n",
              "      <td>mobile web</td>\n",
              "      <td>fl</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>cash_loan</td>\n",
              "      <td>1513728000000000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  created_date location_in_query  ... category_debt_type           time_index\n",
              "0   12/27/2017       san antonio  ...    debt_settlement  1514332800000000000\n",
              "1    1/10/2018          honolulu  ...    debt_settlement  1515542400000000000\n",
              "2   12/15/2017           atlanta  ...    debt_settlement  1513296000000000000\n",
              "3     1/6/2018          honolulu  ...    debt_settlement  1515196800000000000\n",
              "4   12/20/2017     South Beachmi  ...          cash_loan  1513728000000000000\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPPwozZleIPE"
      },
      "source": [
        "Replace boolean values with integer 0 or 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsMqd7btoWyl"
      },
      "source": [
        "# replacing boolean values with integer 0 or 1\n",
        "clicks['is_activated'] = np.where(clicks['is_activated']==True, 0, 1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHyiAXHJJxIO",
        "outputId": "69a5097e-40b8-41d1-e9e9-6037742d09d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check counts per class\n",
        "clicks.is_activated.value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    87407\n",
              "0     6787\n",
              "Name: is_activated, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL2EUIgA5UES"
      },
      "source": [
        "As shown above there are missing values in different columns. We can take a closer look at the statistics  using the below command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWuFLjeK5SrD",
        "outputId": "0d0bf16b-64a5-4b54-bede-9f66db75f8fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(clicks.isnull().sum())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created_date             0\n",
            "location_in_query       15\n",
            "platform                 0\n",
            "campaign_state           6\n",
            "in_city                  0\n",
            "is_prime                 0\n",
            "is_hardship              0\n",
            "is_activated             0\n",
            "category_debt_type    9859\n",
            "time_index               0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERVTLJd5x7lS"
      },
      "source": [
        "# Incorporating Date and Time\n",
        "I use time/date as two main features: 1) as a categorical variable 2) as a continuous normalized number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcIpAy6jx6ru"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "clicks[['time_index']] = scaler.fit_transform(clicks[['time_index']])\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sByCN3q_8Ssy"
      },
      "source": [
        "# Imputation\n",
        "There are missing values in three categorical columns that should be imputed: `location_in_query`, `campaign_state`, and `category_debt_type`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DFo9-Fn8UCB",
        "outputId": "f43c19d6-7189-41a2-ae41-4a2ef38a528f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "states = ['al', 'ak', 'az', 'ar', 'ca', 'co', 'ct', 'dc', 'de', 'fl', 'ga', 'hi', \n",
        "          'id', 'il', 'in', 'ia', 'ks', 'ky', 'la', 'me', 'md', 'ma', 'mi', 'mn',\n",
        "          'ms', 'mo', 'mt', 'ne', 'nv', 'nh', 'nj', 'nm', 'ny', 'nc', 'nd', 'oh',\n",
        "          'ok', 'or', 'pa', 'ri', 'sc', 'sd', 'tn', 'tx', 'ut', 'vt', 'va', 'wa', \n",
        "          'wv', 'wi', 'wy']\n",
        "\n",
        "# also imputing states where the value is a number\n",
        "clicks.loc[~clicks['campaign_state'].isin(states),'campaign_state'] = np.nan\n",
        "\n",
        "#imputing campaign_state with the most frequent state\n",
        "clicks['campaign_state'].fillna(clicks['campaign_state'].mode()[0], inplace = True)\n",
        "\n",
        "#imputing location_in_query with the unknown_location\n",
        "clicks['location_in_query'].fillna('unknown_location', inplace = True)\n",
        "\n",
        "#imputing category_debt_type with the most frequent value\n",
        "clicks['category_debt_type'].fillna(clicks['category_debt_type'].mode()[0], inplace = True)\n",
        "\n",
        "print(clicks.isnull().sum())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created_date          0\n",
            "location_in_query     0\n",
            "platform              0\n",
            "campaign_state        0\n",
            "in_city               0\n",
            "is_prime              0\n",
            "is_hardship           0\n",
            "is_activated          0\n",
            "category_debt_type    0\n",
            "time_index            0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy0_gJB9QLfs"
      },
      "source": [
        "# Balance the data\n",
        "As the training data is imbalanced, we need to adjust the number of positive vs negaive labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIJAhYUcQMTQ",
        "outputId": "c1c17f18-1916-47fa-aef7-462290ea5a8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "data = clicks.copy()\n",
        "\n",
        "#check the length of each class\n",
        "print('oringal data class size:\\n',data.is_activated.value_counts(), '\\n')\n",
        "\n",
        "#creating subsets\n",
        "data_not_activated = data[np.array(data.is_activated) == 0]\n",
        "data_activated = data[np.array(data.is_activated) == 1]\n",
        "\n",
        "#upsampling of the minorty class\n",
        "n_samples = len(data_activated)\n",
        "\n",
        "#downsampling of the minorty class\n",
        "#n_samples = len(data_not_activated)\n",
        "\n",
        "data_not_activated_resampled = resample(data_not_activated, n_samples = n_samples, random_state = 0)\n",
        "data_activated_resampled = resample(data_activated, n_samples = n_samples, random_state = 0)\n",
        "\n",
        "#merged data back together\n",
        "data_resampled = pd.concat([data_not_activated_resampled, data_activated_resampled])\n",
        "\n",
        "#shuffle the data\n",
        "data_resampled = data_resampled.sample(frac = 1) \n",
        "\n",
        "#check the final stats\n",
        "print('resampled data class size:\\n', data_resampled.is_activated.value_counts())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "oringal data class size:\n",
            " 1    87407\n",
            "0     6787\n",
            "Name: is_activated, dtype: int64 \n",
            "\n",
            "resampled data class size:\n",
            " 1    87407\n",
            "0    87407\n",
            "Name: is_activated, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33DmvIBctJM4"
      },
      "source": [
        "# Split the Data \n",
        "One important step is always to split the data into train, validation and test. We accomplish this by the two times running the train_test_split function from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPtH1FtJWDog",
        "outputId": "92dc860f-c16a-4209-f7a8-fbc6f0db8b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# splitting the data\n",
        "\n",
        "# the test data will be used only after the model is trained\n",
        "train_valid, test = train_test_split(data_resampled, test_size = 0.2, shuffle = True) \n",
        "\n",
        "# the valid data will be used during the training but not for the training, only for evaluations per epoch\n",
        "train, valid = train_test_split(train_valid, test_size = 0.25, shuffle = True) \n",
        "\n",
        "#printig their length\n",
        "print('training data size:', len(train))\n",
        "print('validation data size:', len(valid))\n",
        "print('testing data size:', len(test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data size: 104888\n",
            "validation data size: 34963\n",
            "testing data size: 34963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKqkkM0FHm9-"
      },
      "source": [
        "# Creating TensorFlow Ready Datasets\n",
        "To prepare the input data for the TensorFlow data pipeline, we need to put to in sliced batches.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQcif9mbu8lj"
      },
      "source": [
        "def create_dataset(data, batch_size=512):\n",
        "  df = data.copy()\n",
        "  labels = df.pop('is_activated')\n",
        "  \n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
        "\n",
        "  # shuffle the dataset\n",
        "  dataset = dataset.shuffle(buffer_size=len(df))\n",
        "\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  return dataset\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4fAUARdwtyZ"
      },
      "source": [
        "train_data = create_dataset(train)\n",
        "val_data = create_dataset(valid)\n",
        "test_data = create_dataset(test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdlShm_XXNV3"
      },
      "source": [
        "# Feature Columns\n",
        "To create the list of what feature to put in the model, we use the `feature_column` module from `TensorFlow`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDQo7ggnYDzE",
        "outputId": "37a2f9d0-05a2-4711-db94-811e3e2857b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check each variable's number of unique values\n",
        "for i in clicks.columns:\n",
        "  print(i, len(clicks[i].unique()), clicks[i].dtype)  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created_date 32 object\n",
            "location_in_query 797 object\n",
            "platform 3 object\n",
            "campaign_state 43 object\n",
            "in_city 2 int64\n",
            "is_prime 2 int64\n",
            "is_hardship 2 int64\n",
            "is_activated 2 int64\n",
            "category_debt_type 4 object\n",
            "time_index 32 float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlZutCcGbzyS",
        "outputId": "b4d3dcca-2a5c-4e27-c886-34ce689a3797",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check for errors\n",
        "clicks.platform.unique()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mobile web', 'desktop web', 'undefined platform'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxBl9RB32JN9"
      },
      "source": [
        "from tensorflow import feature_column\n",
        "\n",
        "feature_columns = []\n",
        "\n",
        "#first numerical columns\n",
        "for col_name in ['in_city', 'is_prime', 'is_hardship', 'time_index']:\n",
        "  feature_columns.append(feature_column.numeric_column(col_name))\n",
        "\n",
        "# indicator columns\n",
        "indicator_column_names = ['platform', 'category_debt_type']\n",
        "for col_name in indicator_column_names:\n",
        "  categorical_column = feature_column.categorical_column_with_vocabulary_list(col_name, clicks[col_name].unique())\n",
        "  indicator_column = feature_column.indicator_column(categorical_column)\n",
        "  feature_columns.append(indicator_column)\n",
        "\n",
        "# embedding cateogorical columns\n",
        "embeding_columns = ['created_date', 'campaign_state']\n",
        "for col_name in embeding_columns:\n",
        "  vocab = clicks[col_name].unique()\n",
        "  categorical_column = feature_column.categorical_column_with_vocabulary_list(col_name, vocab)\n",
        "  column_embedding = feature_column.embedding_column(categorical_column, dimension= 10)#int(len(vocab) *.3))\n",
        "  feature_columns.append(column_embedding)\n",
        "  \n",
        "# crossed columns\n",
        "campaign_state = feature_column.categorical_column_with_vocabulary_list('campaign_state', clicks.campaign_state.unique())\n",
        "location_in_query = feature_column.categorical_column_with_vocabulary_list('location_in_query', clicks.location_in_query.unique())\n",
        "state_location = feature_column.crossed_column([campaign_state, location_in_query], hash_bucket_size=100)\n",
        "feature_columns.append(feature_column.indicator_column(state_location))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUZJXlg5BQGN"
      },
      "source": [
        "# Model\n",
        "I used a neural network model with four main layers:\n",
        "- An input layer of all features\n",
        "- A dense layer of 1024 neurons with 50% dropout and ‘ReLU’ activation\n",
        "- A dense layer of 128 neurons with 50% dropout and ‘ReLU’ activation\n",
        "- A final single neuron layer of outputs with ‘sigmoid’ activation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJoQGsPvXjxq"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(layers.DenseFeatures(feature_columns))\n",
        "\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQttFSVVey0e"
      },
      "source": [
        "I used four main metrics for our binary classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi_LwJamlbbq"
      },
      "source": [
        "# four main metrics for our binary classification.\n",
        "metrics = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "]\n",
        "\n",
        "metrics_names =  ['loss','accuracy', 'auc', 'precision', 'recall']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2spvXtQe3L-"
      },
      "source": [
        "- I used the binary cross entropy function as my loss function that should be optimized.\n",
        "\n",
        "- Because this is a binary classification, the Adam (Adaptive Moment Estimation) optimizer function should perform better than the generic SGD (Stochastic Gradient Descent).\n",
        "\n",
        "- After tuning the 0.001 learning rate showed a reasonable performance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYuAQaR0fp4O"
      },
      "source": [
        "#model being compiled\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate= 0.001),\n",
        "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics = metrics)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-IOgQn_1l3S",
        "outputId": "fe8b9dec-ddd1-4485-fd4b-ccaf0aa9ddcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class_weight = {1: 1,\n",
        "                0: 0.82}\n",
        "\n",
        "history = model.fit(train_data,\n",
        "                    validation_data = val_data, \n",
        "                    class_weight = class_weight,\n",
        "                    epochs=500)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'created_date': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>, 'location_in_query': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=string>, 'platform': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=string>, 'campaign_state': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>, 'in_city': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=int64>, 'is_prime': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=int64>, 'is_hardship': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=int64>, 'category_debt_type': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'time_index': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'created_date': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>, 'location_in_query': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=string>, 'platform': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=string>, 'campaign_state': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>, 'in_city': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=int64>, 'is_prime': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=int64>, 'is_hardship': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=int64>, 'category_debt_type': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'time_index': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "203/205 [============================>.] - ETA: 0s - loss: 0.6038 - accuracy: 0.5659 - auc: 0.6133 - precision: 0.5505 - recall: 0.7236WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'created_date': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>, 'location_in_query': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=string>, 'platform': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=string>, 'campaign_state': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>, 'in_city': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=int64>, 'is_prime': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=int64>, 'is_hardship': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=int64>, 'category_debt_type': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'time_index': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.6037 - accuracy: 0.5659 - auc: 0.6137 - precision: 0.5503 - recall: 0.7240 - val_loss: 0.6647 - val_accuracy: 0.5820 - val_auc: 0.6391 - val_precision: 0.5614 - val_recall: 0.7488\n",
            "Epoch 2/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.5903 - accuracy: 0.5937 - auc: 0.6473 - precision: 0.5773 - recall: 0.7018 - val_loss: 0.6558 - val_accuracy: 0.5912 - val_auc: 0.6601 - val_precision: 0.5667 - val_recall: 0.7744\n",
            "Epoch 3/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.5793 - accuracy: 0.6092 - auc: 0.6694 - precision: 0.5926 - recall: 0.7005 - val_loss: 0.6374 - val_accuracy: 0.6216 - val_auc: 0.6857 - val_precision: 0.6081 - val_recall: 0.6837\n",
            "Epoch 4/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.5679 - accuracy: 0.6260 - auc: 0.6903 - precision: 0.6108 - recall: 0.6962 - val_loss: 0.6232 - val_accuracy: 0.6356 - val_auc: 0.7049 - val_precision: 0.6180 - val_recall: 0.7102\n",
            "Epoch 5/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.5552 - accuracy: 0.6399 - auc: 0.7098 - precision: 0.6264 - recall: 0.6945 - val_loss: 0.6095 - val_accuracy: 0.6534 - val_auc: 0.7233 - val_precision: 0.6465 - val_recall: 0.6769\n",
            "Epoch 6/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.5437 - accuracy: 0.6542 - auc: 0.7268 - precision: 0.6409 - recall: 0.7023 - val_loss: 0.5963 - val_accuracy: 0.6569 - val_auc: 0.7362 - val_precision: 0.6402 - val_recall: 0.7163\n",
            "Epoch 7/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.5336 - accuracy: 0.6597 - auc: 0.7384 - precision: 0.6461 - recall: 0.7073 - val_loss: 0.5866 - val_accuracy: 0.6646 - val_auc: 0.7483 - val_precision: 0.6476 - val_recall: 0.7218\n",
            "Epoch 8/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.5260 - accuracy: 0.6677 - auc: 0.7485 - precision: 0.6532 - recall: 0.7160 - val_loss: 0.5776 - val_accuracy: 0.6745 - val_auc: 0.7579 - val_precision: 0.6617 - val_recall: 0.7142\n",
            "Epoch 9/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.5187 - accuracy: 0.6724 - auc: 0.7557 - precision: 0.6605 - recall: 0.7105 - val_loss: 0.5688 - val_accuracy: 0.6782 - val_auc: 0.7661 - val_precision: 0.6592 - val_recall: 0.7378\n",
            "Epoch 10/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.5138 - accuracy: 0.6768 - auc: 0.7615 - precision: 0.6649 - recall: 0.7138 - val_loss: 0.5620 - val_accuracy: 0.6877 - val_auc: 0.7728 - val_precision: 0.6843 - val_recall: 0.6968\n",
            "Epoch 11/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.5057 - accuracy: 0.6867 - auc: 0.7709 - precision: 0.6749 - recall: 0.7210 - val_loss: 0.5557 - val_accuracy: 0.6917 - val_auc: 0.7770 - val_precision: 0.6850 - val_recall: 0.7096\n",
            "Epoch 12/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.5024 - accuracy: 0.6863 - auc: 0.7735 - precision: 0.6744 - recall: 0.7212 - val_loss: 0.5543 - val_accuracy: 0.6919 - val_auc: 0.7789 - val_precision: 0.6908 - val_recall: 0.6947\n",
            "Epoch 13/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4987 - accuracy: 0.6893 - auc: 0.7776 - precision: 0.6783 - recall: 0.7210 - val_loss: 0.5447 - val_accuracy: 0.6992 - val_auc: 0.7836 - val_precision: 0.7059 - val_recall: 0.6829\n",
            "Epoch 14/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4951 - accuracy: 0.6922 - auc: 0.7809 - precision: 0.6815 - recall: 0.7224 - val_loss: 0.5441 - val_accuracy: 0.7005 - val_auc: 0.7887 - val_precision: 0.6953 - val_recall: 0.7138\n",
            "Epoch 15/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4917 - accuracy: 0.6960 - auc: 0.7852 - precision: 0.6856 - recall: 0.7251 - val_loss: 0.5395 - val_accuracy: 0.7027 - val_auc: 0.7923 - val_precision: 0.6973 - val_recall: 0.7163\n",
            "Epoch 16/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4861 - accuracy: 0.7012 - auc: 0.7905 - precision: 0.6927 - recall: 0.7239 - val_loss: 0.5353 - val_accuracy: 0.7086 - val_auc: 0.7956 - val_precision: 0.7027 - val_recall: 0.7229\n",
            "Epoch 17/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4849 - accuracy: 0.7003 - auc: 0.7906 - precision: 0.6898 - recall: 0.7288 - val_loss: 0.5320 - val_accuracy: 0.7095 - val_auc: 0.7964 - val_precision: 0.7186 - val_recall: 0.6886\n",
            "Epoch 18/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4820 - accuracy: 0.7029 - auc: 0.7937 - precision: 0.6958 - recall: 0.7219 - val_loss: 0.5325 - val_accuracy: 0.7082 - val_auc: 0.7972 - val_precision: 0.7074 - val_recall: 0.7098\n",
            "Epoch 19/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4800 - accuracy: 0.7052 - auc: 0.7963 - precision: 0.6961 - recall: 0.7291 - val_loss: 0.5307 - val_accuracy: 0.7116 - val_auc: 0.8008 - val_precision: 0.7182 - val_recall: 0.6965\n",
            "Epoch 20/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4769 - accuracy: 0.7070 - auc: 0.7988 - precision: 0.6969 - recall: 0.7335 - val_loss: 0.5251 - val_accuracy: 0.7104 - val_auc: 0.8026 - val_precision: 0.7063 - val_recall: 0.7203\n",
            "Epoch 21/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4751 - accuracy: 0.7084 - auc: 0.7998 - precision: 0.7008 - recall: 0.7278 - val_loss: 0.5243 - val_accuracy: 0.7136 - val_auc: 0.8042 - val_precision: 0.7130 - val_recall: 0.7150\n",
            "Epoch 22/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4730 - accuracy: 0.7100 - auc: 0.8020 - precision: 0.7006 - recall: 0.7340 - val_loss: 0.5224 - val_accuracy: 0.7160 - val_auc: 0.8048 - val_precision: 0.7233 - val_recall: 0.6995\n",
            "Epoch 23/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4705 - accuracy: 0.7111 - auc: 0.8035 - precision: 0.7055 - recall: 0.7253 - val_loss: 0.5212 - val_accuracy: 0.7118 - val_auc: 0.8066 - val_precision: 0.7016 - val_recall: 0.7368\n",
            "Epoch 24/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4683 - accuracy: 0.7124 - auc: 0.8061 - precision: 0.7037 - recall: 0.7344 - val_loss: 0.5195 - val_accuracy: 0.7136 - val_auc: 0.8077 - val_precision: 0.7040 - val_recall: 0.7371\n",
            "Epoch 25/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4658 - accuracy: 0.7151 - auc: 0.8079 - precision: 0.7081 - recall: 0.7327 - val_loss: 0.5180 - val_accuracy: 0.7179 - val_auc: 0.8082 - val_precision: 0.7163 - val_recall: 0.7216\n",
            "Epoch 26/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4648 - accuracy: 0.7153 - auc: 0.8093 - precision: 0.7067 - recall: 0.7368 - val_loss: 0.5153 - val_accuracy: 0.7175 - val_auc: 0.8103 - val_precision: 0.7125 - val_recall: 0.7293\n",
            "Epoch 27/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4629 - accuracy: 0.7167 - auc: 0.8106 - precision: 0.7114 - recall: 0.7297 - val_loss: 0.5137 - val_accuracy: 0.7181 - val_auc: 0.8111 - val_precision: 0.7144 - val_recall: 0.7266\n",
            "Epoch 28/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4630 - accuracy: 0.7167 - auc: 0.8107 - precision: 0.7128 - recall: 0.7265 - val_loss: 0.5131 - val_accuracy: 0.7199 - val_auc: 0.8117 - val_precision: 0.7168 - val_recall: 0.7269\n",
            "Epoch 29/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4623 - accuracy: 0.7172 - auc: 0.8106 - precision: 0.7127 - recall: 0.7283 - val_loss: 0.5148 - val_accuracy: 0.7169 - val_auc: 0.8126 - val_precision: 0.7015 - val_recall: 0.7549\n",
            "Epoch 30/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4603 - accuracy: 0.7172 - auc: 0.8123 - precision: 0.7098 - recall: 0.7355 - val_loss: 0.5135 - val_accuracy: 0.7228 - val_auc: 0.8132 - val_precision: 0.7233 - val_recall: 0.7217\n",
            "Epoch 31/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4592 - accuracy: 0.7198 - auc: 0.8141 - precision: 0.7132 - recall: 0.7360 - val_loss: 0.5103 - val_accuracy: 0.7230 - val_auc: 0.8141 - val_precision: 0.7272 - val_recall: 0.7136\n",
            "Epoch 32/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4576 - accuracy: 0.7207 - auc: 0.8156 - precision: 0.7135 - recall: 0.7382 - val_loss: 0.5109 - val_accuracy: 0.7233 - val_auc: 0.8147 - val_precision: 0.7202 - val_recall: 0.7300\n",
            "Epoch 33/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4564 - accuracy: 0.7205 - auc: 0.8160 - precision: 0.7138 - recall: 0.7368 - val_loss: 0.5069 - val_accuracy: 0.7283 - val_auc: 0.8161 - val_precision: 0.7380 - val_recall: 0.7076\n",
            "Epoch 34/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4546 - accuracy: 0.7194 - auc: 0.8165 - precision: 0.7129 - recall: 0.7353 - val_loss: 0.5081 - val_accuracy: 0.7245 - val_auc: 0.8147 - val_precision: 0.7319 - val_recall: 0.7083\n",
            "Epoch 35/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4541 - accuracy: 0.7223 - auc: 0.8176 - precision: 0.7166 - recall: 0.7362 - val_loss: 0.5076 - val_accuracy: 0.7222 - val_auc: 0.8155 - val_precision: 0.7198 - val_recall: 0.7274\n",
            "Epoch 36/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4533 - accuracy: 0.7224 - auc: 0.8180 - precision: 0.7152 - recall: 0.7396 - val_loss: 0.5056 - val_accuracy: 0.7264 - val_auc: 0.8177 - val_precision: 0.7247 - val_recall: 0.7301\n",
            "Epoch 37/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4524 - accuracy: 0.7213 - auc: 0.8189 - precision: 0.7132 - recall: 0.7412 - val_loss: 0.5038 - val_accuracy: 0.7251 - val_auc: 0.8177 - val_precision: 0.7333 - val_recall: 0.7074\n",
            "Epoch 38/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4518 - accuracy: 0.7245 - auc: 0.8199 - precision: 0.7191 - recall: 0.7374 - val_loss: 0.5048 - val_accuracy: 0.7254 - val_auc: 0.8180 - val_precision: 0.7281 - val_recall: 0.7195\n",
            "Epoch 39/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4507 - accuracy: 0.7243 - auc: 0.8209 - precision: 0.7188 - recall: 0.7373 - val_loss: 0.5044 - val_accuracy: 0.7268 - val_auc: 0.8186 - val_precision: 0.7310 - val_recall: 0.7174\n",
            "Epoch 40/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4499 - accuracy: 0.7253 - auc: 0.8208 - precision: 0.7196 - recall: 0.7389 - val_loss: 0.5027 - val_accuracy: 0.7254 - val_auc: 0.8194 - val_precision: 0.7254 - val_recall: 0.7252\n",
            "Epoch 41/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4491 - accuracy: 0.7261 - auc: 0.8219 - precision: 0.7199 - recall: 0.7407 - val_loss: 0.5018 - val_accuracy: 0.7263 - val_auc: 0.8186 - val_precision: 0.7291 - val_recall: 0.7202\n",
            "Epoch 42/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4470 - accuracy: 0.7266 - auc: 0.8232 - precision: 0.7211 - recall: 0.7396 - val_loss: 0.5004 - val_accuracy: 0.7271 - val_auc: 0.8204 - val_precision: 0.7275 - val_recall: 0.7260\n",
            "Epoch 43/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4470 - accuracy: 0.7259 - auc: 0.8227 - precision: 0.7191 - recall: 0.7419 - val_loss: 0.5015 - val_accuracy: 0.7285 - val_auc: 0.8203 - val_precision: 0.7350 - val_recall: 0.7147\n",
            "Epoch 44/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4470 - accuracy: 0.7261 - auc: 0.8230 - precision: 0.7192 - recall: 0.7425 - val_loss: 0.5021 - val_accuracy: 0.7276 - val_auc: 0.8201 - val_precision: 0.7281 - val_recall: 0.7265\n",
            "Epoch 45/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4469 - accuracy: 0.7278 - auc: 0.8240 - precision: 0.7227 - recall: 0.7397 - val_loss: 0.5012 - val_accuracy: 0.7316 - val_auc: 0.8216 - val_precision: 0.7389 - val_recall: 0.7163\n",
            "Epoch 46/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4451 - accuracy: 0.7277 - auc: 0.8239 - precision: 0.7232 - recall: 0.7385 - val_loss: 0.5008 - val_accuracy: 0.7320 - val_auc: 0.8218 - val_precision: 0.7381 - val_recall: 0.7192\n",
            "Epoch 47/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4440 - accuracy: 0.7288 - auc: 0.8254 - precision: 0.7243 - recall: 0.7396 - val_loss: 0.5006 - val_accuracy: 0.7303 - val_auc: 0.8211 - val_precision: 0.7383 - val_recall: 0.7134\n",
            "Epoch 48/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4438 - accuracy: 0.7313 - auc: 0.8260 - precision: 0.7299 - recall: 0.7348 - val_loss: 0.5001 - val_accuracy: 0.7276 - val_auc: 0.8215 - val_precision: 0.7223 - val_recall: 0.7396\n",
            "Epoch 49/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4444 - accuracy: 0.7272 - auc: 0.8246 - precision: 0.7227 - recall: 0.7380 - val_loss: 0.4985 - val_accuracy: 0.7304 - val_auc: 0.8229 - val_precision: 0.7309 - val_recall: 0.7291\n",
            "Epoch 50/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4434 - accuracy: 0.7289 - auc: 0.8259 - precision: 0.7221 - recall: 0.7449 - val_loss: 0.5001 - val_accuracy: 0.7296 - val_auc: 0.8224 - val_precision: 0.7275 - val_recall: 0.7343\n",
            "Epoch 51/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4425 - accuracy: 0.7278 - auc: 0.8263 - precision: 0.7206 - recall: 0.7446 - val_loss: 0.4987 - val_accuracy: 0.7298 - val_auc: 0.8223 - val_precision: 0.7327 - val_recall: 0.7236\n",
            "Epoch 52/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4429 - accuracy: 0.7285 - auc: 0.8263 - precision: 0.7246 - recall: 0.7377 - val_loss: 0.4993 - val_accuracy: 0.7287 - val_auc: 0.8229 - val_precision: 0.7277 - val_recall: 0.7305\n",
            "Epoch 53/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4428 - accuracy: 0.7296 - auc: 0.8266 - precision: 0.7249 - recall: 0.7407 - val_loss: 0.4978 - val_accuracy: 0.7301 - val_auc: 0.8232 - val_precision: 0.7363 - val_recall: 0.7167\n",
            "Epoch 54/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4409 - accuracy: 0.7308 - auc: 0.8279 - precision: 0.7262 - recall: 0.7415 - val_loss: 0.4974 - val_accuracy: 0.7294 - val_auc: 0.8233 - val_precision: 0.7289 - val_recall: 0.7305\n",
            "Epoch 55/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4416 - accuracy: 0.7307 - auc: 0.8270 - precision: 0.7309 - recall: 0.7308 - val_loss: 0.4952 - val_accuracy: 0.7324 - val_auc: 0.8239 - val_precision: 0.7433 - val_recall: 0.7101\n",
            "Epoch 56/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4402 - accuracy: 0.7320 - auc: 0.8281 - precision: 0.7341 - recall: 0.7280 - val_loss: 0.4954 - val_accuracy: 0.7335 - val_auc: 0.8243 - val_precision: 0.7401 - val_recall: 0.7196\n",
            "Epoch 57/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4398 - accuracy: 0.7317 - auc: 0.8288 - precision: 0.7305 - recall: 0.7349 - val_loss: 0.4954 - val_accuracy: 0.7309 - val_auc: 0.8245 - val_precision: 0.7313 - val_recall: 0.7298\n",
            "Epoch 58/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4397 - accuracy: 0.7326 - auc: 0.8289 - precision: 0.7303 - recall: 0.7383 - val_loss: 0.4943 - val_accuracy: 0.7309 - val_auc: 0.8253 - val_precision: 0.7276 - val_recall: 0.7380\n",
            "Epoch 59/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4387 - accuracy: 0.7317 - auc: 0.8292 - precision: 0.7292 - recall: 0.7378 - val_loss: 0.4955 - val_accuracy: 0.7322 - val_auc: 0.8248 - val_precision: 0.7304 - val_recall: 0.7358\n",
            "Epoch 60/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4386 - accuracy: 0.7337 - auc: 0.8296 - precision: 0.7354 - recall: 0.7307 - val_loss: 0.4965 - val_accuracy: 0.7316 - val_auc: 0.8251 - val_precision: 0.7307 - val_recall: 0.7335\n",
            "Epoch 61/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4381 - accuracy: 0.7320 - auc: 0.8294 - precision: 0.7301 - recall: 0.7365 - val_loss: 0.4964 - val_accuracy: 0.7334 - val_auc: 0.8245 - val_precision: 0.7431 - val_recall: 0.7134\n",
            "Epoch 62/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4378 - accuracy: 0.7327 - auc: 0.8305 - precision: 0.7303 - recall: 0.7386 - val_loss: 0.4950 - val_accuracy: 0.7353 - val_auc: 0.8253 - val_precision: 0.7469 - val_recall: 0.7117\n",
            "Epoch 63/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4375 - accuracy: 0.7345 - auc: 0.8303 - precision: 0.7377 - recall: 0.7284 - val_loss: 0.4937 - val_accuracy: 0.7351 - val_auc: 0.8260 - val_precision: 0.7395 - val_recall: 0.7258\n",
            "Epoch 64/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4373 - accuracy: 0.7330 - auc: 0.8305 - precision: 0.7344 - recall: 0.7304 - val_loss: 0.4945 - val_accuracy: 0.7323 - val_auc: 0.8248 - val_precision: 0.7363 - val_recall: 0.7236\n",
            "Epoch 65/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4364 - accuracy: 0.7356 - auc: 0.8319 - precision: 0.7322 - recall: 0.7434 - val_loss: 0.4935 - val_accuracy: 0.7305 - val_auc: 0.8261 - val_precision: 0.7221 - val_recall: 0.7491\n",
            "Epoch 66/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4362 - accuracy: 0.7339 - auc: 0.8311 - precision: 0.7301 - recall: 0.7427 - val_loss: 0.4947 - val_accuracy: 0.7293 - val_auc: 0.8252 - val_precision: 0.7217 - val_recall: 0.7461\n",
            "Epoch 67/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4360 - accuracy: 0.7333 - auc: 0.8312 - precision: 0.7277 - recall: 0.7461 - val_loss: 0.4942 - val_accuracy: 0.7318 - val_auc: 0.8253 - val_precision: 0.7349 - val_recall: 0.7249\n",
            "Epoch 68/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4369 - accuracy: 0.7327 - auc: 0.8311 - precision: 0.7292 - recall: 0.7408 - val_loss: 0.4937 - val_accuracy: 0.7307 - val_auc: 0.8252 - val_precision: 0.7308 - val_recall: 0.7306\n",
            "Epoch 69/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4340 - accuracy: 0.7347 - auc: 0.8327 - precision: 0.7318 - recall: 0.7417 - val_loss: 0.4921 - val_accuracy: 0.7309 - val_auc: 0.8265 - val_precision: 0.7289 - val_recall: 0.7351\n",
            "Epoch 70/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4342 - accuracy: 0.7348 - auc: 0.8328 - precision: 0.7335 - recall: 0.7381 - val_loss: 0.4943 - val_accuracy: 0.7351 - val_auc: 0.8251 - val_precision: 0.7457 - val_recall: 0.7134\n",
            "Epoch 71/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4338 - accuracy: 0.7359 - auc: 0.8330 - precision: 0.7385 - recall: 0.7311 - val_loss: 0.4922 - val_accuracy: 0.7356 - val_auc: 0.8265 - val_precision: 0.7425 - val_recall: 0.7212\n",
            "Epoch 72/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4345 - accuracy: 0.7344 - auc: 0.8323 - precision: 0.7359 - recall: 0.7319 - val_loss: 0.4943 - val_accuracy: 0.7338 - val_auc: 0.8256 - val_precision: 0.7361 - val_recall: 0.7289\n",
            "Epoch 73/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4336 - accuracy: 0.7361 - auc: 0.8330 - precision: 0.7385 - recall: 0.7317 - val_loss: 0.4921 - val_accuracy: 0.7353 - val_auc: 0.8263 - val_precision: 0.7512 - val_recall: 0.7037\n",
            "Epoch 74/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4342 - accuracy: 0.7372 - auc: 0.8329 - precision: 0.7414 - recall: 0.7291 - val_loss: 0.4928 - val_accuracy: 0.7362 - val_auc: 0.8264 - val_precision: 0.7510 - val_recall: 0.7065\n",
            "Epoch 75/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4341 - accuracy: 0.7364 - auc: 0.8331 - precision: 0.7368 - recall: 0.7361 - val_loss: 0.4926 - val_accuracy: 0.7375 - val_auc: 0.8268 - val_precision: 0.7539 - val_recall: 0.7052\n",
            "Epoch 76/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4330 - accuracy: 0.7383 - auc: 0.8341 - precision: 0.7408 - recall: 0.7339 - val_loss: 0.4923 - val_accuracy: 0.7312 - val_auc: 0.8265 - val_precision: 0.7284 - val_recall: 0.7374\n",
            "Epoch 77/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4323 - accuracy: 0.7369 - auc: 0.8343 - precision: 0.7388 - recall: 0.7336 - val_loss: 0.4927 - val_accuracy: 0.7305 - val_auc: 0.8271 - val_precision: 0.7251 - val_recall: 0.7425\n",
            "Epoch 78/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4334 - accuracy: 0.7382 - auc: 0.8338 - precision: 0.7412 - recall: 0.7325 - val_loss: 0.4920 - val_accuracy: 0.7361 - val_auc: 0.8265 - val_precision: 0.7442 - val_recall: 0.7194\n",
            "Epoch 79/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4319 - accuracy: 0.7373 - auc: 0.8347 - precision: 0.7366 - recall: 0.7392 - val_loss: 0.4918 - val_accuracy: 0.7359 - val_auc: 0.8263 - val_precision: 0.7501 - val_recall: 0.7074\n",
            "Epoch 80/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4311 - accuracy: 0.7360 - auc: 0.8349 - precision: 0.7331 - recall: 0.7427 - val_loss: 0.4910 - val_accuracy: 0.7375 - val_auc: 0.8271 - val_precision: 0.7516 - val_recall: 0.7093\n",
            "Epoch 81/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4323 - accuracy: 0.7377 - auc: 0.8348 - precision: 0.7381 - recall: 0.7376 - val_loss: 0.4894 - val_accuracy: 0.7356 - val_auc: 0.8277 - val_precision: 0.7446 - val_recall: 0.7170\n",
            "Epoch 82/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4308 - accuracy: 0.7380 - auc: 0.8352 - precision: 0.7404 - recall: 0.7335 - val_loss: 0.4908 - val_accuracy: 0.7355 - val_auc: 0.8270 - val_precision: 0.7437 - val_recall: 0.7186\n",
            "Epoch 83/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4317 - accuracy: 0.7376 - auc: 0.8346 - precision: 0.7407 - recall: 0.7316 - val_loss: 0.4909 - val_accuracy: 0.7353 - val_auc: 0.8279 - val_precision: 0.7428 - val_recall: 0.7197\n",
            "Epoch 84/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4312 - accuracy: 0.7363 - auc: 0.8346 - precision: 0.7356 - recall: 0.7385 - val_loss: 0.4894 - val_accuracy: 0.7350 - val_auc: 0.8283 - val_precision: 0.7344 - val_recall: 0.7360\n",
            "Epoch 85/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4307 - accuracy: 0.7373 - auc: 0.8349 - precision: 0.7365 - recall: 0.7394 - val_loss: 0.4905 - val_accuracy: 0.7294 - val_auc: 0.8273 - val_precision: 0.7220 - val_recall: 0.7459\n",
            "Epoch 86/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4310 - accuracy: 0.7354 - auc: 0.8348 - precision: 0.7282 - recall: 0.7518 - val_loss: 0.4925 - val_accuracy: 0.7351 - val_auc: 0.8266 - val_precision: 0.7439 - val_recall: 0.7171\n",
            "Epoch 87/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4306 - accuracy: 0.7391 - auc: 0.8353 - precision: 0.7431 - recall: 0.7314 - val_loss: 0.4895 - val_accuracy: 0.7379 - val_auc: 0.8281 - val_precision: 0.7480 - val_recall: 0.7174\n",
            "Epoch 88/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4318 - accuracy: 0.7371 - auc: 0.8344 - precision: 0.7412 - recall: 0.7292 - val_loss: 0.4891 - val_accuracy: 0.7379 - val_auc: 0.8280 - val_precision: 0.7535 - val_recall: 0.7071\n",
            "Epoch 89/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4309 - accuracy: 0.7385 - auc: 0.8352 - precision: 0.7442 - recall: 0.7274 - val_loss: 0.4891 - val_accuracy: 0.7367 - val_auc: 0.8283 - val_precision: 0.7463 - val_recall: 0.7170\n",
            "Epoch 90/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4310 - accuracy: 0.7365 - auc: 0.8349 - precision: 0.7363 - recall: 0.7375 - val_loss: 0.4906 - val_accuracy: 0.7358 - val_auc: 0.8274 - val_precision: 0.7434 - val_recall: 0.7202\n",
            "Epoch 91/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4284 - accuracy: 0.7394 - auc: 0.8367 - precision: 0.7430 - recall: 0.7327 - val_loss: 0.4881 - val_accuracy: 0.7366 - val_auc: 0.8285 - val_precision: 0.7452 - val_recall: 0.7190\n",
            "Epoch 92/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4297 - accuracy: 0.7391 - auc: 0.8357 - precision: 0.7436 - recall: 0.7304 - val_loss: 0.4914 - val_accuracy: 0.7359 - val_auc: 0.8274 - val_precision: 0.7452 - val_recall: 0.7170\n",
            "Epoch 93/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4285 - accuracy: 0.7392 - auc: 0.8371 - precision: 0.7433 - recall: 0.7311 - val_loss: 0.4885 - val_accuracy: 0.7361 - val_auc: 0.8288 - val_precision: 0.7429 - val_recall: 0.7220\n",
            "Epoch 94/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4285 - accuracy: 0.7390 - auc: 0.8370 - precision: 0.7384 - recall: 0.7408 - val_loss: 0.4891 - val_accuracy: 0.7357 - val_auc: 0.8278 - val_precision: 0.7445 - val_recall: 0.7175\n",
            "Epoch 95/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4276 - accuracy: 0.7384 - auc: 0.8372 - precision: 0.7360 - recall: 0.7441 - val_loss: 0.4902 - val_accuracy: 0.7342 - val_auc: 0.8282 - val_precision: 0.7387 - val_recall: 0.7246\n",
            "Epoch 96/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4293 - accuracy: 0.7390 - auc: 0.8364 - precision: 0.7415 - recall: 0.7345 - val_loss: 0.4904 - val_accuracy: 0.7363 - val_auc: 0.8283 - val_precision: 0.7405 - val_recall: 0.7276\n",
            "Epoch 97/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4279 - accuracy: 0.7408 - auc: 0.8374 - precision: 0.7439 - recall: 0.7349 - val_loss: 0.4887 - val_accuracy: 0.7370 - val_auc: 0.8284 - val_precision: 0.7474 - val_recall: 0.7158\n",
            "Epoch 98/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4286 - accuracy: 0.7392 - auc: 0.8365 - precision: 0.7447 - recall: 0.7285 - val_loss: 0.4899 - val_accuracy: 0.7378 - val_auc: 0.8285 - val_precision: 0.7489 - val_recall: 0.7155\n",
            "Epoch 99/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4288 - accuracy: 0.7387 - auc: 0.8369 - precision: 0.7382 - recall: 0.7401 - val_loss: 0.4883 - val_accuracy: 0.7354 - val_auc: 0.8287 - val_precision: 0.7401 - val_recall: 0.7255\n",
            "Epoch 100/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4280 - accuracy: 0.7378 - auc: 0.8369 - precision: 0.7348 - recall: 0.7448 - val_loss: 0.4874 - val_accuracy: 0.7367 - val_auc: 0.8288 - val_precision: 0.7428 - val_recall: 0.7240\n",
            "Epoch 101/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4280 - accuracy: 0.7403 - auc: 0.8369 - precision: 0.7446 - recall: 0.7322 - val_loss: 0.4895 - val_accuracy: 0.7370 - val_auc: 0.8281 - val_precision: 0.7449 - val_recall: 0.7208\n",
            "Epoch 102/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4277 - accuracy: 0.7396 - auc: 0.8372 - precision: 0.7420 - recall: 0.7353 - val_loss: 0.4889 - val_accuracy: 0.7392 - val_auc: 0.8286 - val_precision: 0.7514 - val_recall: 0.7147\n",
            "Epoch 103/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4280 - accuracy: 0.7405 - auc: 0.8372 - precision: 0.7455 - recall: 0.7307 - val_loss: 0.4898 - val_accuracy: 0.7395 - val_auc: 0.8280 - val_precision: 0.7527 - val_recall: 0.7133\n",
            "Epoch 104/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4278 - accuracy: 0.7403 - auc: 0.8373 - precision: 0.7419 - recall: 0.7375 - val_loss: 0.4879 - val_accuracy: 0.7396 - val_auc: 0.8291 - val_precision: 0.7559 - val_recall: 0.7078\n",
            "Epoch 105/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4278 - accuracy: 0.7394 - auc: 0.8366 - precision: 0.7449 - recall: 0.7288 - val_loss: 0.4902 - val_accuracy: 0.7343 - val_auc: 0.8288 - val_precision: 0.7304 - val_recall: 0.7427\n",
            "Epoch 106/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4280 - accuracy: 0.7414 - auc: 0.8376 - precision: 0.7444 - recall: 0.7358 - val_loss: 0.4884 - val_accuracy: 0.7355 - val_auc: 0.8293 - val_precision: 0.7366 - val_recall: 0.7333\n",
            "Epoch 107/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4270 - accuracy: 0.7410 - auc: 0.8375 - precision: 0.7455 - recall: 0.7324 - val_loss: 0.4892 - val_accuracy: 0.7366 - val_auc: 0.8283 - val_precision: 0.7508 - val_recall: 0.7081\n",
            "Epoch 108/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4266 - accuracy: 0.7417 - auc: 0.8387 - precision: 0.7482 - recall: 0.7291 - val_loss: 0.4893 - val_accuracy: 0.7382 - val_auc: 0.8285 - val_precision: 0.7473 - val_recall: 0.7197\n",
            "Epoch 109/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4265 - accuracy: 0.7402 - auc: 0.8379 - precision: 0.7423 - recall: 0.7363 - val_loss: 0.4883 - val_accuracy: 0.7405 - val_auc: 0.8290 - val_precision: 0.7570 - val_recall: 0.7083\n",
            "Epoch 110/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4273 - accuracy: 0.7409 - auc: 0.8375 - precision: 0.7461 - recall: 0.7310 - val_loss: 0.4899 - val_accuracy: 0.7378 - val_auc: 0.8282 - val_precision: 0.7473 - val_recall: 0.7185\n",
            "Epoch 111/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4265 - accuracy: 0.7417 - auc: 0.8385 - precision: 0.7468 - recall: 0.7321 - val_loss: 0.4887 - val_accuracy: 0.7398 - val_auc: 0.8286 - val_precision: 0.7579 - val_recall: 0.7047\n",
            "Epoch 112/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4265 - accuracy: 0.7402 - auc: 0.8379 - precision: 0.7441 - recall: 0.7327 - val_loss: 0.4897 - val_accuracy: 0.7361 - val_auc: 0.8287 - val_precision: 0.7410 - val_recall: 0.7258\n",
            "Epoch 113/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4256 - accuracy: 0.7421 - auc: 0.8390 - precision: 0.7459 - recall: 0.7350 - val_loss: 0.4876 - val_accuracy: 0.7394 - val_auc: 0.8296 - val_precision: 0.7543 - val_recall: 0.7099\n",
            "Epoch 114/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4264 - accuracy: 0.7411 - auc: 0.8378 - precision: 0.7470 - recall: 0.7296 - val_loss: 0.4875 - val_accuracy: 0.7384 - val_auc: 0.8301 - val_precision: 0.7474 - val_recall: 0.7201\n",
            "Epoch 115/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4257 - accuracy: 0.7409 - auc: 0.8385 - precision: 0.7430 - recall: 0.7373 - val_loss: 0.4877 - val_accuracy: 0.7354 - val_auc: 0.8292 - val_precision: 0.7394 - val_recall: 0.7268\n",
            "Epoch 116/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4259 - accuracy: 0.7403 - auc: 0.8388 - precision: 0.7391 - recall: 0.7433 - val_loss: 0.4888 - val_accuracy: 0.7356 - val_auc: 0.8290 - val_precision: 0.7391 - val_recall: 0.7282\n",
            "Epoch 117/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4267 - accuracy: 0.7409 - auc: 0.8381 - precision: 0.7409 - recall: 0.7413 - val_loss: 0.4882 - val_accuracy: 0.7386 - val_auc: 0.8293 - val_precision: 0.7529 - val_recall: 0.7103\n",
            "Epoch 118/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4246 - accuracy: 0.7428 - auc: 0.8398 - precision: 0.7437 - recall: 0.7414 - val_loss: 0.4876 - val_accuracy: 0.7361 - val_auc: 0.8297 - val_precision: 0.7396 - val_recall: 0.7285\n",
            "Epoch 119/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4248 - accuracy: 0.7393 - auc: 0.8386 - precision: 0.7394 - recall: 0.7396 - val_loss: 0.4885 - val_accuracy: 0.7377 - val_auc: 0.8289 - val_precision: 0.7560 - val_recall: 0.7020\n",
            "Epoch 120/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4247 - accuracy: 0.7417 - auc: 0.8391 - precision: 0.7465 - recall: 0.7323 - val_loss: 0.4888 - val_accuracy: 0.7387 - val_auc: 0.8293 - val_precision: 0.7519 - val_recall: 0.7124\n",
            "Epoch 121/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4242 - accuracy: 0.7434 - auc: 0.8400 - precision: 0.7482 - recall: 0.7341 - val_loss: 0.4883 - val_accuracy: 0.7380 - val_auc: 0.8294 - val_precision: 0.7490 - val_recall: 0.7157\n",
            "Epoch 122/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4252 - accuracy: 0.7423 - auc: 0.8397 - precision: 0.7471 - recall: 0.7330 - val_loss: 0.4885 - val_accuracy: 0.7380 - val_auc: 0.8292 - val_precision: 0.7531 - val_recall: 0.7081\n",
            "Epoch 123/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4257 - accuracy: 0.7400 - auc: 0.8383 - precision: 0.7423 - recall: 0.7358 - val_loss: 0.4882 - val_accuracy: 0.7357 - val_auc: 0.8290 - val_precision: 0.7404 - val_recall: 0.7260\n",
            "Epoch 124/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4243 - accuracy: 0.7401 - auc: 0.8392 - precision: 0.7380 - recall: 0.7451 - val_loss: 0.4894 - val_accuracy: 0.7348 - val_auc: 0.8286 - val_precision: 0.7340 - val_recall: 0.7365\n",
            "Epoch 125/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4237 - accuracy: 0.7417 - auc: 0.8401 - precision: 0.7408 - recall: 0.7442 - val_loss: 0.4872 - val_accuracy: 0.7358 - val_auc: 0.8300 - val_precision: 0.7366 - val_recall: 0.7342\n",
            "Epoch 126/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4233 - accuracy: 0.7409 - auc: 0.8399 - precision: 0.7393 - recall: 0.7449 - val_loss: 0.4866 - val_accuracy: 0.7386 - val_auc: 0.8304 - val_precision: 0.7550 - val_recall: 0.7062\n",
            "Epoch 127/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4247 - accuracy: 0.7406 - auc: 0.8393 - precision: 0.7454 - recall: 0.7315 - val_loss: 0.4889 - val_accuracy: 0.7365 - val_auc: 0.8293 - val_precision: 0.7437 - val_recall: 0.7214\n",
            "Epoch 128/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4233 - accuracy: 0.7429 - auc: 0.8404 - precision: 0.7470 - recall: 0.7352 - val_loss: 0.4878 - val_accuracy: 0.7390 - val_auc: 0.8297 - val_precision: 0.7563 - val_recall: 0.7051\n",
            "Epoch 129/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4249 - accuracy: 0.7428 - auc: 0.8393 - precision: 0.7483 - recall: 0.7323 - val_loss: 0.4888 - val_accuracy: 0.7380 - val_auc: 0.8292 - val_precision: 0.7524 - val_recall: 0.7092\n",
            "Epoch 130/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4233 - accuracy: 0.7435 - auc: 0.8407 - precision: 0.7492 - recall: 0.7325 - val_loss: 0.4876 - val_accuracy: 0.7366 - val_auc: 0.8297 - val_precision: 0.7421 - val_recall: 0.7252\n",
            "Epoch 131/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4234 - accuracy: 0.7417 - auc: 0.8397 - precision: 0.7454 - recall: 0.7348 - val_loss: 0.4880 - val_accuracy: 0.7388 - val_auc: 0.8298 - val_precision: 0.7554 - val_recall: 0.7062\n",
            "Epoch 132/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4234 - accuracy: 0.7427 - auc: 0.8404 - precision: 0.7478 - recall: 0.7332 - val_loss: 0.4876 - val_accuracy: 0.7352 - val_auc: 0.8297 - val_precision: 0.7382 - val_recall: 0.7288\n",
            "Epoch 133/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4234 - accuracy: 0.7405 - auc: 0.8400 - precision: 0.7379 - recall: 0.7465 - val_loss: 0.4875 - val_accuracy: 0.7380 - val_auc: 0.8297 - val_precision: 0.7506 - val_recall: 0.7126\n",
            "Epoch 134/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4232 - accuracy: 0.7433 - auc: 0.8404 - precision: 0.7474 - recall: 0.7356 - val_loss: 0.4890 - val_accuracy: 0.7372 - val_auc: 0.8296 - val_precision: 0.7457 - val_recall: 0.7198\n",
            "Epoch 135/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4237 - accuracy: 0.7413 - auc: 0.8397 - precision: 0.7431 - recall: 0.7381 - val_loss: 0.4885 - val_accuracy: 0.7370 - val_auc: 0.8298 - val_precision: 0.7463 - val_recall: 0.7181\n",
            "Epoch 136/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4235 - accuracy: 0.7421 - auc: 0.8401 - precision: 0.7489 - recall: 0.7290 - val_loss: 0.4870 - val_accuracy: 0.7377 - val_auc: 0.8302 - val_precision: 0.7496 - val_recall: 0.7137\n",
            "Epoch 137/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4226 - accuracy: 0.7420 - auc: 0.8407 - precision: 0.7405 - recall: 0.7457 - val_loss: 0.4882 - val_accuracy: 0.7335 - val_auc: 0.8303 - val_precision: 0.7279 - val_recall: 0.7458\n",
            "Epoch 138/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4222 - accuracy: 0.7422 - auc: 0.8411 - precision: 0.7392 - recall: 0.7491 - val_loss: 0.4864 - val_accuracy: 0.7349 - val_auc: 0.8306 - val_precision: 0.7327 - val_recall: 0.7396\n",
            "Epoch 139/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4232 - accuracy: 0.7421 - auc: 0.8405 - precision: 0.7387 - recall: 0.7498 - val_loss: 0.4872 - val_accuracy: 0.7363 - val_auc: 0.8301 - val_precision: 0.7335 - val_recall: 0.7422\n",
            "Epoch 140/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4226 - accuracy: 0.7431 - auc: 0.8410 - precision: 0.7405 - recall: 0.7492 - val_loss: 0.4873 - val_accuracy: 0.7361 - val_auc: 0.8297 - val_precision: 0.7357 - val_recall: 0.7370\n",
            "Epoch 141/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4229 - accuracy: 0.7430 - auc: 0.8407 - precision: 0.7433 - recall: 0.7429 - val_loss: 0.4881 - val_accuracy: 0.7374 - val_auc: 0.8297 - val_precision: 0.7403 - val_recall: 0.7311\n",
            "Epoch 142/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4226 - accuracy: 0.7426 - auc: 0.8411 - precision: 0.7408 - recall: 0.7470 - val_loss: 0.4889 - val_accuracy: 0.7347 - val_auc: 0.8296 - val_precision: 0.7308 - val_recall: 0.7429\n",
            "Epoch 143/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4233 - accuracy: 0.7422 - auc: 0.8403 - precision: 0.7398 - recall: 0.7478 - val_loss: 0.4875 - val_accuracy: 0.7378 - val_auc: 0.8301 - val_precision: 0.7483 - val_recall: 0.7165\n",
            "Epoch 144/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4220 - accuracy: 0.7427 - auc: 0.8409 - precision: 0.7468 - recall: 0.7350 - val_loss: 0.4873 - val_accuracy: 0.7363 - val_auc: 0.8301 - val_precision: 0.7358 - val_recall: 0.7372\n",
            "Epoch 145/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4219 - accuracy: 0.7425 - auc: 0.8412 - precision: 0.7413 - recall: 0.7454 - val_loss: 0.4870 - val_accuracy: 0.7353 - val_auc: 0.8300 - val_precision: 0.7377 - val_recall: 0.7302\n",
            "Epoch 146/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4229 - accuracy: 0.7415 - auc: 0.8407 - precision: 0.7394 - recall: 0.7464 - val_loss: 0.4885 - val_accuracy: 0.7349 - val_auc: 0.8295 - val_precision: 0.7354 - val_recall: 0.7336\n",
            "Epoch 147/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4221 - accuracy: 0.7419 - auc: 0.8411 - precision: 0.7389 - recall: 0.7489 - val_loss: 0.4879 - val_accuracy: 0.7357 - val_auc: 0.8303 - val_precision: 0.7315 - val_recall: 0.7446\n",
            "Epoch 148/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4212 - accuracy: 0.7418 - auc: 0.8418 - precision: 0.7388 - recall: 0.7486 - val_loss: 0.4878 - val_accuracy: 0.7359 - val_auc: 0.8304 - val_precision: 0.7339 - val_recall: 0.7401\n",
            "Epoch 149/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4220 - accuracy: 0.7430 - auc: 0.8415 - precision: 0.7410 - recall: 0.7476 - val_loss: 0.4876 - val_accuracy: 0.7361 - val_auc: 0.8305 - val_precision: 0.7357 - val_recall: 0.7368\n",
            "Epoch 150/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4202 - accuracy: 0.7431 - auc: 0.8425 - precision: 0.7414 - recall: 0.7471 - val_loss: 0.4870 - val_accuracy: 0.7368 - val_auc: 0.8307 - val_precision: 0.7412 - val_recall: 0.7277\n",
            "Epoch 151/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4214 - accuracy: 0.7411 - auc: 0.8406 - precision: 0.7404 - recall: 0.7430 - val_loss: 0.4870 - val_accuracy: 0.7366 - val_auc: 0.8307 - val_precision: 0.7361 - val_recall: 0.7375\n",
            "Epoch 152/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4222 - accuracy: 0.7421 - auc: 0.8417 - precision: 0.7405 - recall: 0.7462 - val_loss: 0.4867 - val_accuracy: 0.7376 - val_auc: 0.8308 - val_precision: 0.7372 - val_recall: 0.7384\n",
            "Epoch 153/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4217 - accuracy: 0.7430 - auc: 0.8414 - precision: 0.7411 - recall: 0.7474 - val_loss: 0.4873 - val_accuracy: 0.7377 - val_auc: 0.8303 - val_precision: 0.7429 - val_recall: 0.7270\n",
            "Epoch 154/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4204 - accuracy: 0.7442 - auc: 0.8428 - precision: 0.7435 - recall: 0.7462 - val_loss: 0.4857 - val_accuracy: 0.7356 - val_auc: 0.8311 - val_precision: 0.7352 - val_recall: 0.7363\n",
            "Epoch 155/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4221 - accuracy: 0.7420 - auc: 0.8408 - precision: 0.7401 - recall: 0.7465 - val_loss: 0.4873 - val_accuracy: 0.7360 - val_auc: 0.8303 - val_precision: 0.7358 - val_recall: 0.7364\n",
            "Epoch 156/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4214 - accuracy: 0.7433 - auc: 0.8418 - precision: 0.7448 - recall: 0.7408 - val_loss: 0.4858 - val_accuracy: 0.7384 - val_auc: 0.8308 - val_precision: 0.7535 - val_recall: 0.7084\n",
            "Epoch 157/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4211 - accuracy: 0.7437 - auc: 0.8414 - precision: 0.7493 - recall: 0.7329 - val_loss: 0.4855 - val_accuracy: 0.7385 - val_auc: 0.8311 - val_precision: 0.7456 - val_recall: 0.7239\n",
            "Epoch 158/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4213 - accuracy: 0.7445 - auc: 0.8421 - precision: 0.7472 - recall: 0.7396 - val_loss: 0.4854 - val_accuracy: 0.7362 - val_auc: 0.8311 - val_precision: 0.7366 - val_recall: 0.7352\n",
            "Epoch 159/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4202 - accuracy: 0.7435 - auc: 0.8423 - precision: 0.7408 - recall: 0.7499 - val_loss: 0.4849 - val_accuracy: 0.7379 - val_auc: 0.8312 - val_precision: 0.7422 - val_recall: 0.7290\n",
            "Epoch 160/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4209 - accuracy: 0.7423 - auc: 0.8416 - precision: 0.7389 - recall: 0.7499 - val_loss: 0.4859 - val_accuracy: 0.7359 - val_auc: 0.8311 - val_precision: 0.7347 - val_recall: 0.7383\n",
            "Epoch 161/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4212 - accuracy: 0.7427 - auc: 0.8418 - precision: 0.7400 - recall: 0.7489 - val_loss: 0.4849 - val_accuracy: 0.7374 - val_auc: 0.8316 - val_precision: 0.7387 - val_recall: 0.7345\n",
            "Epoch 162/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4207 - accuracy: 0.7423 - auc: 0.8417 - precision: 0.7408 - recall: 0.7460 - val_loss: 0.4858 - val_accuracy: 0.7376 - val_auc: 0.8312 - val_precision: 0.7412 - val_recall: 0.7300\n",
            "Epoch 163/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4200 - accuracy: 0.7437 - auc: 0.8425 - precision: 0.7439 - recall: 0.7439 - val_loss: 0.4865 - val_accuracy: 0.7399 - val_auc: 0.8312 - val_precision: 0.7483 - val_recall: 0.7229\n",
            "Epoch 164/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4208 - accuracy: 0.7442 - auc: 0.8420 - precision: 0.7476 - recall: 0.7378 - val_loss: 0.4859 - val_accuracy: 0.7376 - val_auc: 0.8312 - val_precision: 0.7417 - val_recall: 0.7290\n",
            "Epoch 165/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4202 - accuracy: 0.7432 - auc: 0.8418 - precision: 0.7420 - recall: 0.7463 - val_loss: 0.4874 - val_accuracy: 0.7369 - val_auc: 0.8307 - val_precision: 0.7379 - val_recall: 0.7347\n",
            "Epoch 166/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4204 - accuracy: 0.7442 - auc: 0.8428 - precision: 0.7431 - recall: 0.7471 - val_loss: 0.4868 - val_accuracy: 0.7360 - val_auc: 0.8304 - val_precision: 0.7357 - val_recall: 0.7365\n",
            "Epoch 167/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4193 - accuracy: 0.7438 - auc: 0.8429 - precision: 0.7421 - recall: 0.7478 - val_loss: 0.4862 - val_accuracy: 0.7356 - val_auc: 0.8308 - val_precision: 0.7351 - val_recall: 0.7367\n",
            "Epoch 168/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4205 - accuracy: 0.7428 - auc: 0.8419 - precision: 0.7421 - recall: 0.7448 - val_loss: 0.4860 - val_accuracy: 0.7390 - val_auc: 0.8310 - val_precision: 0.7501 - val_recall: 0.7166\n",
            "Epoch 169/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4206 - accuracy: 0.7444 - auc: 0.8419 - precision: 0.7468 - recall: 0.7402 - val_loss: 0.4861 - val_accuracy: 0.7375 - val_auc: 0.8310 - val_precision: 0.7382 - val_recall: 0.7357\n",
            "Epoch 170/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4195 - accuracy: 0.7443 - auc: 0.8425 - precision: 0.7478 - recall: 0.7377 - val_loss: 0.4850 - val_accuracy: 0.7371 - val_auc: 0.8314 - val_precision: 0.7389 - val_recall: 0.7333\n",
            "Epoch 171/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4201 - accuracy: 0.7441 - auc: 0.8424 - precision: 0.7440 - recall: 0.7448 - val_loss: 0.4861 - val_accuracy: 0.7374 - val_auc: 0.8309 - val_precision: 0.7393 - val_recall: 0.7333\n",
            "Epoch 172/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4203 - accuracy: 0.7445 - auc: 0.8427 - precision: 0.7449 - recall: 0.7442 - val_loss: 0.4870 - val_accuracy: 0.7351 - val_auc: 0.8302 - val_precision: 0.7365 - val_recall: 0.7319\n",
            "Epoch 173/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4197 - accuracy: 0.7453 - auc: 0.8431 - precision: 0.7441 - recall: 0.7484 - val_loss: 0.4870 - val_accuracy: 0.7355 - val_auc: 0.8307 - val_precision: 0.7307 - val_recall: 0.7456\n",
            "Epoch 174/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4200 - accuracy: 0.7437 - auc: 0.8425 - precision: 0.7408 - recall: 0.7502 - val_loss: 0.4853 - val_accuracy: 0.7368 - val_auc: 0.8308 - val_precision: 0.7414 - val_recall: 0.7271\n",
            "Epoch 175/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4198 - accuracy: 0.7437 - auc: 0.8422 - precision: 0.7422 - recall: 0.7473 - val_loss: 0.4859 - val_accuracy: 0.7378 - val_auc: 0.8304 - val_precision: 0.7420 - val_recall: 0.7289\n",
            "Epoch 176/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4202 - accuracy: 0.7440 - auc: 0.8427 - precision: 0.7445 - recall: 0.7433 - val_loss: 0.4855 - val_accuracy: 0.7379 - val_auc: 0.8307 - val_precision: 0.7395 - val_recall: 0.7344\n",
            "Epoch 177/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4184 - accuracy: 0.7443 - auc: 0.8434 - precision: 0.7415 - recall: 0.7507 - val_loss: 0.4858 - val_accuracy: 0.7363 - val_auc: 0.8312 - val_precision: 0.7352 - val_recall: 0.7384\n",
            "Epoch 178/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4189 - accuracy: 0.7453 - auc: 0.8438 - precision: 0.7429 - recall: 0.7508 - val_loss: 0.4869 - val_accuracy: 0.7368 - val_auc: 0.8308 - val_precision: 0.7346 - val_recall: 0.7412\n",
            "Epoch 179/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4198 - accuracy: 0.7439 - auc: 0.8426 - precision: 0.7395 - recall: 0.7538 - val_loss: 0.4866 - val_accuracy: 0.7374 - val_auc: 0.8310 - val_precision: 0.7356 - val_recall: 0.7410\n",
            "Epoch 180/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4196 - accuracy: 0.7425 - auc: 0.8424 - precision: 0.7399 - recall: 0.7486 - val_loss: 0.4872 - val_accuracy: 0.7362 - val_auc: 0.8318 - val_precision: 0.7296 - val_recall: 0.7507\n",
            "Epoch 181/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4196 - accuracy: 0.7431 - auc: 0.8428 - precision: 0.7389 - recall: 0.7525 - val_loss: 0.4872 - val_accuracy: 0.7366 - val_auc: 0.8305 - val_precision: 0.7371 - val_recall: 0.7353\n",
            "Epoch 182/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4200 - accuracy: 0.7432 - auc: 0.8430 - precision: 0.7414 - recall: 0.7474 - val_loss: 0.4873 - val_accuracy: 0.7357 - val_auc: 0.8313 - val_precision: 0.7335 - val_recall: 0.7402\n",
            "Epoch 183/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4188 - accuracy: 0.7442 - auc: 0.8432 - precision: 0.7405 - recall: 0.7524 - val_loss: 0.4862 - val_accuracy: 0.7366 - val_auc: 0.8309 - val_precision: 0.7409 - val_recall: 0.7277\n",
            "Epoch 184/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4186 - accuracy: 0.7451 - auc: 0.8434 - precision: 0.7504 - recall: 0.7350 - val_loss: 0.4853 - val_accuracy: 0.7397 - val_auc: 0.8313 - val_precision: 0.7509 - val_recall: 0.7174\n",
            "Epoch 185/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4178 - accuracy: 0.7460 - auc: 0.8447 - precision: 0.7468 - recall: 0.7449 - val_loss: 0.4858 - val_accuracy: 0.7355 - val_auc: 0.8308 - val_precision: 0.7343 - val_recall: 0.7381\n",
            "Epoch 186/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4186 - accuracy: 0.7454 - auc: 0.8438 - precision: 0.7447 - recall: 0.7474 - val_loss: 0.4845 - val_accuracy: 0.7384 - val_auc: 0.8315 - val_precision: 0.7450 - val_recall: 0.7246\n",
            "Epoch 187/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4190 - accuracy: 0.7448 - auc: 0.8429 - precision: 0.7477 - recall: 0.7396 - val_loss: 0.4849 - val_accuracy: 0.7379 - val_auc: 0.8315 - val_precision: 0.7499 - val_recall: 0.7138\n",
            "Epoch 188/500\n",
            "205/205 [==============================] - 3s 14ms/step - loss: 0.4195 - accuracy: 0.7446 - auc: 0.8425 - precision: 0.7460 - recall: 0.7421 - val_loss: 0.4860 - val_accuracy: 0.7372 - val_auc: 0.8309 - val_precision: 0.7421 - val_recall: 0.7270\n",
            "Epoch 189/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4192 - accuracy: 0.7440 - auc: 0.8429 - precision: 0.7406 - recall: 0.7515 - val_loss: 0.4855 - val_accuracy: 0.7366 - val_auc: 0.8313 - val_precision: 0.7398 - val_recall: 0.7300\n",
            "Epoch 190/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4188 - accuracy: 0.7454 - auc: 0.8436 - precision: 0.7439 - recall: 0.7491 - val_loss: 0.4868 - val_accuracy: 0.7368 - val_auc: 0.8310 - val_precision: 0.7385 - val_recall: 0.7331\n",
            "Epoch 191/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4188 - accuracy: 0.7455 - auc: 0.8436 - precision: 0.7438 - recall: 0.7495 - val_loss: 0.4866 - val_accuracy: 0.7367 - val_auc: 0.8312 - val_precision: 0.7393 - val_recall: 0.7312\n",
            "Epoch 192/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4184 - accuracy: 0.7449 - auc: 0.8439 - precision: 0.7465 - recall: 0.7422 - val_loss: 0.4857 - val_accuracy: 0.7370 - val_auc: 0.8309 - val_precision: 0.7442 - val_recall: 0.7224\n",
            "Epoch 193/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4189 - accuracy: 0.7450 - auc: 0.8430 - precision: 0.7487 - recall: 0.7381 - val_loss: 0.4857 - val_accuracy: 0.7364 - val_auc: 0.8315 - val_precision: 0.7407 - val_recall: 0.7274\n",
            "Epoch 194/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4182 - accuracy: 0.7454 - auc: 0.8439 - precision: 0.7447 - recall: 0.7475 - val_loss: 0.4846 - val_accuracy: 0.7367 - val_auc: 0.8316 - val_precision: 0.7381 - val_recall: 0.7337\n",
            "Epoch 195/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4179 - accuracy: 0.7462 - auc: 0.8440 - precision: 0.7454 - recall: 0.7483 - val_loss: 0.4858 - val_accuracy: 0.7351 - val_auc: 0.8320 - val_precision: 0.7303 - val_recall: 0.7454\n",
            "Epoch 196/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4178 - accuracy: 0.7451 - auc: 0.8440 - precision: 0.7428 - recall: 0.7503 - val_loss: 0.4878 - val_accuracy: 0.7362 - val_auc: 0.8310 - val_precision: 0.7359 - val_recall: 0.7369\n",
            "Epoch 197/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4183 - accuracy: 0.7457 - auc: 0.8441 - precision: 0.7424 - recall: 0.7529 - val_loss: 0.4866 - val_accuracy: 0.7346 - val_auc: 0.8309 - val_precision: 0.7329 - val_recall: 0.7381\n",
            "Epoch 198/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4172 - accuracy: 0.7461 - auc: 0.8448 - precision: 0.7422 - recall: 0.7546 - val_loss: 0.4860 - val_accuracy: 0.7353 - val_auc: 0.8312 - val_precision: 0.7328 - val_recall: 0.7404\n",
            "Epoch 199/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4183 - accuracy: 0.7443 - auc: 0.8436 - precision: 0.7399 - recall: 0.7539 - val_loss: 0.4860 - val_accuracy: 0.7360 - val_auc: 0.8312 - val_precision: 0.7353 - val_recall: 0.7376\n",
            "Epoch 200/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4180 - accuracy: 0.7447 - auc: 0.8439 - precision: 0.7407 - recall: 0.7536 - val_loss: 0.4854 - val_accuracy: 0.7356 - val_auc: 0.8317 - val_precision: 0.7314 - val_recall: 0.7445\n",
            "Epoch 201/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4168 - accuracy: 0.7459 - auc: 0.8450 - precision: 0.7419 - recall: 0.7547 - val_loss: 0.4840 - val_accuracy: 0.7357 - val_auc: 0.8319 - val_precision: 0.7355 - val_recall: 0.7362\n",
            "Epoch 202/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4176 - accuracy: 0.7444 - auc: 0.8441 - precision: 0.7430 - recall: 0.7479 - val_loss: 0.4856 - val_accuracy: 0.7346 - val_auc: 0.8312 - val_precision: 0.7324 - val_recall: 0.7392\n",
            "Epoch 203/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4175 - accuracy: 0.7432 - auc: 0.8439 - precision: 0.7381 - recall: 0.7546 - val_loss: 0.4853 - val_accuracy: 0.7366 - val_auc: 0.8319 - val_precision: 0.7363 - val_recall: 0.7372\n",
            "Epoch 204/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4176 - accuracy: 0.7460 - auc: 0.8439 - precision: 0.7447 - recall: 0.7493 - val_loss: 0.4856 - val_accuracy: 0.7371 - val_auc: 0.8318 - val_precision: 0.7366 - val_recall: 0.7380\n",
            "Epoch 205/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4176 - accuracy: 0.7449 - auc: 0.8442 - precision: 0.7410 - recall: 0.7534 - val_loss: 0.4852 - val_accuracy: 0.7365 - val_auc: 0.8314 - val_precision: 0.7363 - val_recall: 0.7368\n",
            "Epoch 206/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4169 - accuracy: 0.7453 - auc: 0.8448 - precision: 0.7432 - recall: 0.7499 - val_loss: 0.4844 - val_accuracy: 0.7368 - val_auc: 0.8316 - val_precision: 0.7352 - val_recall: 0.7399\n",
            "Epoch 207/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4172 - accuracy: 0.7452 - auc: 0.8448 - precision: 0.7417 - recall: 0.7531 - val_loss: 0.4842 - val_accuracy: 0.7351 - val_auc: 0.8317 - val_precision: 0.7328 - val_recall: 0.7401\n",
            "Epoch 208/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4178 - accuracy: 0.7462 - auc: 0.8443 - precision: 0.7422 - recall: 0.7550 - val_loss: 0.4857 - val_accuracy: 0.7357 - val_auc: 0.8317 - val_precision: 0.7305 - val_recall: 0.7470\n",
            "Epoch 209/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4177 - accuracy: 0.7449 - auc: 0.8441 - precision: 0.7414 - recall: 0.7528 - val_loss: 0.4862 - val_accuracy: 0.7363 - val_auc: 0.8314 - val_precision: 0.7309 - val_recall: 0.7478\n",
            "Epoch 210/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4172 - accuracy: 0.7463 - auc: 0.8450 - precision: 0.7421 - recall: 0.7554 - val_loss: 0.4865 - val_accuracy: 0.7364 - val_auc: 0.8319 - val_precision: 0.7314 - val_recall: 0.7472\n",
            "Epoch 211/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4172 - accuracy: 0.7458 - auc: 0.8447 - precision: 0.7432 - recall: 0.7518 - val_loss: 0.4850 - val_accuracy: 0.7370 - val_auc: 0.8318 - val_precision: 0.7338 - val_recall: 0.7435\n",
            "Epoch 212/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4173 - accuracy: 0.7458 - auc: 0.8447 - precision: 0.7433 - recall: 0.7514 - val_loss: 0.4861 - val_accuracy: 0.7353 - val_auc: 0.8316 - val_precision: 0.7306 - val_recall: 0.7452\n",
            "Epoch 213/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4168 - accuracy: 0.7464 - auc: 0.8448 - precision: 0.7441 - recall: 0.7518 - val_loss: 0.4866 - val_accuracy: 0.7362 - val_auc: 0.8319 - val_precision: 0.7315 - val_recall: 0.7462\n",
            "Epoch 214/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4177 - accuracy: 0.7448 - auc: 0.8442 - precision: 0.7429 - recall: 0.7493 - val_loss: 0.4847 - val_accuracy: 0.7369 - val_auc: 0.8320 - val_precision: 0.7334 - val_recall: 0.7443\n",
            "Epoch 215/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4168 - accuracy: 0.7444 - auc: 0.8446 - precision: 0.7400 - recall: 0.7541 - val_loss: 0.4857 - val_accuracy: 0.7370 - val_auc: 0.8318 - val_precision: 0.7359 - val_recall: 0.7392\n",
            "Epoch 216/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4168 - accuracy: 0.7450 - auc: 0.8446 - precision: 0.7399 - recall: 0.7561 - val_loss: 0.4866 - val_accuracy: 0.7379 - val_auc: 0.8321 - val_precision: 0.7376 - val_recall: 0.7384\n",
            "Epoch 217/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4168 - accuracy: 0.7451 - auc: 0.8447 - precision: 0.7419 - recall: 0.7523 - val_loss: 0.4855 - val_accuracy: 0.7358 - val_auc: 0.8316 - val_precision: 0.7316 - val_recall: 0.7448\n",
            "Epoch 218/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4164 - accuracy: 0.7455 - auc: 0.8455 - precision: 0.7419 - recall: 0.7535 - val_loss: 0.4868 - val_accuracy: 0.7365 - val_auc: 0.8316 - val_precision: 0.7343 - val_recall: 0.7409\n",
            "Epoch 219/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4172 - accuracy: 0.7452 - auc: 0.8446 - precision: 0.7396 - recall: 0.7574 - val_loss: 0.4855 - val_accuracy: 0.7382 - val_auc: 0.8322 - val_precision: 0.7388 - val_recall: 0.7369\n",
            "Epoch 220/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4166 - accuracy: 0.7476 - auc: 0.8459 - precision: 0.7422 - recall: 0.7592 - val_loss: 0.4852 - val_accuracy: 0.7373 - val_auc: 0.8324 - val_precision: 0.7334 - val_recall: 0.7454\n",
            "Epoch 221/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4162 - accuracy: 0.7459 - auc: 0.8453 - precision: 0.7430 - recall: 0.7524 - val_loss: 0.4845 - val_accuracy: 0.7387 - val_auc: 0.8322 - val_precision: 0.7420 - val_recall: 0.7316\n",
            "Epoch 222/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4168 - accuracy: 0.7454 - auc: 0.8445 - precision: 0.7434 - recall: 0.7502 - val_loss: 0.4870 - val_accuracy: 0.7380 - val_auc: 0.8317 - val_precision: 0.7374 - val_recall: 0.7390\n",
            "Epoch 223/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4167 - accuracy: 0.7467 - auc: 0.8449 - precision: 0.7447 - recall: 0.7512 - val_loss: 0.4851 - val_accuracy: 0.7369 - val_auc: 0.8322 - val_precision: 0.7358 - val_recall: 0.7391\n",
            "Epoch 224/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4160 - accuracy: 0.7467 - auc: 0.8455 - precision: 0.7447 - recall: 0.7513 - val_loss: 0.4863 - val_accuracy: 0.7381 - val_auc: 0.8316 - val_precision: 0.7376 - val_recall: 0.7391\n",
            "Epoch 225/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4162 - accuracy: 0.7474 - auc: 0.8455 - precision: 0.7461 - recall: 0.7507 - val_loss: 0.4847 - val_accuracy: 0.7374 - val_auc: 0.8324 - val_precision: 0.7357 - val_recall: 0.7408\n",
            "Epoch 226/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4162 - accuracy: 0.7466 - auc: 0.8449 - precision: 0.7439 - recall: 0.7528 - val_loss: 0.4852 - val_accuracy: 0.7365 - val_auc: 0.8315 - val_precision: 0.7379 - val_recall: 0.7335\n",
            "Epoch 227/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4159 - accuracy: 0.7463 - auc: 0.8453 - precision: 0.7451 - recall: 0.7492 - val_loss: 0.4844 - val_accuracy: 0.7364 - val_auc: 0.8320 - val_precision: 0.7358 - val_recall: 0.7375\n",
            "Epoch 228/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4162 - accuracy: 0.7464 - auc: 0.8453 - precision: 0.7439 - recall: 0.7521 - val_loss: 0.4851 - val_accuracy: 0.7371 - val_auc: 0.8323 - val_precision: 0.7322 - val_recall: 0.7475\n",
            "Epoch 229/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4159 - accuracy: 0.7479 - auc: 0.8457 - precision: 0.7456 - recall: 0.7531 - val_loss: 0.4864 - val_accuracy: 0.7357 - val_auc: 0.8323 - val_precision: 0.7284 - val_recall: 0.7518\n",
            "Epoch 230/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4164 - accuracy: 0.7460 - auc: 0.8448 - precision: 0.7429 - recall: 0.7529 - val_loss: 0.4843 - val_accuracy: 0.7374 - val_auc: 0.8322 - val_precision: 0.7363 - val_recall: 0.7394\n",
            "Epoch 231/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4164 - accuracy: 0.7463 - auc: 0.8452 - precision: 0.7423 - recall: 0.7549 - val_loss: 0.4859 - val_accuracy: 0.7375 - val_auc: 0.8320 - val_precision: 0.7368 - val_recall: 0.7389\n",
            "Epoch 232/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4161 - accuracy: 0.7455 - auc: 0.8456 - precision: 0.7429 - recall: 0.7514 - val_loss: 0.4862 - val_accuracy: 0.7385 - val_auc: 0.8320 - val_precision: 0.7364 - val_recall: 0.7429\n",
            "Epoch 233/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4163 - accuracy: 0.7455 - auc: 0.8448 - precision: 0.7436 - recall: 0.7498 - val_loss: 0.4862 - val_accuracy: 0.7365 - val_auc: 0.8323 - val_precision: 0.7308 - val_recall: 0.7487\n",
            "Epoch 234/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4159 - accuracy: 0.7464 - auc: 0.8452 - precision: 0.7433 - recall: 0.7533 - val_loss: 0.4854 - val_accuracy: 0.7382 - val_auc: 0.8319 - val_precision: 0.7387 - val_recall: 0.7372\n",
            "Epoch 235/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4162 - accuracy: 0.7454 - auc: 0.8448 - precision: 0.7438 - recall: 0.7493 - val_loss: 0.4863 - val_accuracy: 0.7371 - val_auc: 0.8324 - val_precision: 0.7338 - val_recall: 0.7442\n",
            "Epoch 236/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4169 - accuracy: 0.7462 - auc: 0.8452 - precision: 0.7439 - recall: 0.7514 - val_loss: 0.4853 - val_accuracy: 0.7372 - val_auc: 0.8319 - val_precision: 0.7361 - val_recall: 0.7395\n",
            "Epoch 237/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4157 - accuracy: 0.7455 - auc: 0.8452 - precision: 0.7424 - recall: 0.7525 - val_loss: 0.4854 - val_accuracy: 0.7401 - val_auc: 0.8317 - val_precision: 0.7457 - val_recall: 0.7286\n",
            "Epoch 238/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4153 - accuracy: 0.7482 - auc: 0.8460 - precision: 0.7479 - recall: 0.7494 - val_loss: 0.4853 - val_accuracy: 0.7382 - val_auc: 0.8321 - val_precision: 0.7393 - val_recall: 0.7359\n",
            "Epoch 239/500\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.4160 - accuracy: 0.7461 - auc: 0.8448 - precision: 0.7445 - recall: 0.7500 - val_loss: 0.4860 - val_accuracy: 0.7375 - val_auc: 0.8322 - val_precision: 0.7334 - val_recall: 0.7463\n",
            "Epoch 240/500\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.4162 - accuracy: 0.7469 - auc: 0.8450 - precision: 0.7456 - recall: 0.7500 - val_loss: 0.4850 - val_accuracy: 0.7391 - val_auc: 0.8321 - val_precision: 0.7415 - val_recall: 0.7340\n",
            "Epoch 241/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4157 - accuracy: 0.7464 - auc: 0.8453 - precision: 0.7452 - recall: 0.7493 - val_loss: 0.4859 - val_accuracy: 0.7375 - val_auc: 0.8325 - val_precision: 0.7350 - val_recall: 0.7428\n",
            "Epoch 242/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4158 - accuracy: 0.7472 - auc: 0.8451 - precision: 0.7458 - recall: 0.7506 - val_loss: 0.4854 - val_accuracy: 0.7371 - val_auc: 0.8323 - val_precision: 0.7366 - val_recall: 0.7381\n",
            "Epoch 243/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4150 - accuracy: 0.7461 - auc: 0.8456 - precision: 0.7422 - recall: 0.7545 - val_loss: 0.4857 - val_accuracy: 0.7373 - val_auc: 0.8319 - val_precision: 0.7388 - val_recall: 0.7341\n",
            "Epoch 244/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4151 - accuracy: 0.7468 - auc: 0.8460 - precision: 0.7456 - recall: 0.7499 - val_loss: 0.4867 - val_accuracy: 0.7376 - val_auc: 0.8319 - val_precision: 0.7396 - val_recall: 0.7333\n",
            "Epoch 245/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4153 - accuracy: 0.7457 - auc: 0.8456 - precision: 0.7466 - recall: 0.7446 - val_loss: 0.4859 - val_accuracy: 0.7375 - val_auc: 0.8326 - val_precision: 0.7329 - val_recall: 0.7474\n",
            "Epoch 246/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4147 - accuracy: 0.7476 - auc: 0.8464 - precision: 0.7441 - recall: 0.7553 - val_loss: 0.4856 - val_accuracy: 0.7390 - val_auc: 0.8321 - val_precision: 0.7438 - val_recall: 0.7289\n",
            "Epoch 247/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4157 - accuracy: 0.7477 - auc: 0.8458 - precision: 0.7464 - recall: 0.7509 - val_loss: 0.4849 - val_accuracy: 0.7383 - val_auc: 0.8324 - val_precision: 0.7376 - val_recall: 0.7397\n",
            "Epoch 248/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4155 - accuracy: 0.7462 - auc: 0.8456 - precision: 0.7418 - recall: 0.7558 - val_loss: 0.4855 - val_accuracy: 0.7372 - val_auc: 0.8324 - val_precision: 0.7354 - val_recall: 0.7408\n",
            "Epoch 249/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4157 - accuracy: 0.7470 - auc: 0.8456 - precision: 0.7447 - recall: 0.7521 - val_loss: 0.4853 - val_accuracy: 0.7380 - val_auc: 0.8325 - val_precision: 0.7331 - val_recall: 0.7484\n",
            "Epoch 250/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4164 - accuracy: 0.7457 - auc: 0.8449 - precision: 0.7428 - recall: 0.7521 - val_loss: 0.4846 - val_accuracy: 0.7375 - val_auc: 0.8324 - val_precision: 0.7354 - val_recall: 0.7419\n",
            "Epoch 251/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4158 - accuracy: 0.7462 - auc: 0.8456 - precision: 0.7446 - recall: 0.7501 - val_loss: 0.4858 - val_accuracy: 0.7361 - val_auc: 0.8322 - val_precision: 0.7327 - val_recall: 0.7432\n",
            "Epoch 252/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4154 - accuracy: 0.7461 - auc: 0.8455 - precision: 0.7430 - recall: 0.7531 - val_loss: 0.4863 - val_accuracy: 0.7363 - val_auc: 0.8320 - val_precision: 0.7313 - val_recall: 0.7468\n",
            "Epoch 253/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4152 - accuracy: 0.7478 - auc: 0.8460 - precision: 0.7452 - recall: 0.7537 - val_loss: 0.4857 - val_accuracy: 0.7358 - val_auc: 0.8323 - val_precision: 0.7294 - val_recall: 0.7498\n",
            "Epoch 254/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4158 - accuracy: 0.7470 - auc: 0.8456 - precision: 0.7435 - recall: 0.7546 - val_loss: 0.4852 - val_accuracy: 0.7379 - val_auc: 0.8321 - val_precision: 0.7404 - val_recall: 0.7327\n",
            "Epoch 255/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4152 - accuracy: 0.7467 - auc: 0.8460 - precision: 0.7450 - recall: 0.7508 - val_loss: 0.4849 - val_accuracy: 0.7374 - val_auc: 0.8318 - val_precision: 0.7410 - val_recall: 0.7300\n",
            "Epoch 256/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4153 - accuracy: 0.7469 - auc: 0.8457 - precision: 0.7437 - recall: 0.7541 - val_loss: 0.4852 - val_accuracy: 0.7377 - val_auc: 0.8323 - val_precision: 0.7405 - val_recall: 0.7318\n",
            "Epoch 257/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4148 - accuracy: 0.7470 - auc: 0.8461 - precision: 0.7452 - recall: 0.7514 - val_loss: 0.4847 - val_accuracy: 0.7364 - val_auc: 0.8324 - val_precision: 0.7353 - val_recall: 0.7385\n",
            "Epoch 258/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4146 - accuracy: 0.7478 - auc: 0.8464 - precision: 0.7465 - recall: 0.7508 - val_loss: 0.4854 - val_accuracy: 0.7379 - val_auc: 0.8324 - val_precision: 0.7402 - val_recall: 0.7332\n",
            "Epoch 259/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4146 - accuracy: 0.7476 - auc: 0.8464 - precision: 0.7463 - recall: 0.7507 - val_loss: 0.4844 - val_accuracy: 0.7408 - val_auc: 0.8323 - val_precision: 0.7547 - val_recall: 0.7135\n",
            "Epoch 260/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4149 - accuracy: 0.7490 - auc: 0.8462 - precision: 0.7508 - recall: 0.7458 - val_loss: 0.4844 - val_accuracy: 0.7364 - val_auc: 0.8324 - val_precision: 0.7357 - val_recall: 0.7379\n",
            "Epoch 261/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4144 - accuracy: 0.7480 - auc: 0.8461 - precision: 0.7474 - recall: 0.7497 - val_loss: 0.4860 - val_accuracy: 0.7374 - val_auc: 0.8323 - val_precision: 0.7368 - val_recall: 0.7386\n",
            "Epoch 262/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4158 - accuracy: 0.7458 - auc: 0.8454 - precision: 0.7433 - recall: 0.7514 - val_loss: 0.4864 - val_accuracy: 0.7371 - val_auc: 0.8324 - val_precision: 0.7344 - val_recall: 0.7426\n",
            "Epoch 263/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4151 - accuracy: 0.7486 - auc: 0.8467 - precision: 0.7476 - recall: 0.7510 - val_loss: 0.4848 - val_accuracy: 0.7378 - val_auc: 0.8322 - val_precision: 0.7410 - val_recall: 0.7309\n",
            "Epoch 264/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4141 - accuracy: 0.7472 - auc: 0.8470 - precision: 0.7455 - recall: 0.7510 - val_loss: 0.4851 - val_accuracy: 0.7368 - val_auc: 0.8325 - val_precision: 0.7358 - val_recall: 0.7385\n",
            "Epoch 265/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4145 - accuracy: 0.7467 - auc: 0.8460 - precision: 0.7443 - recall: 0.7521 - val_loss: 0.4868 - val_accuracy: 0.7359 - val_auc: 0.8323 - val_precision: 0.7371 - val_recall: 0.7334\n",
            "Epoch 266/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4143 - accuracy: 0.7470 - auc: 0.8464 - precision: 0.7461 - recall: 0.7492 - val_loss: 0.4870 - val_accuracy: 0.7365 - val_auc: 0.8321 - val_precision: 0.7346 - val_recall: 0.7404\n",
            "Epoch 267/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4142 - accuracy: 0.7476 - auc: 0.8463 - precision: 0.7453 - recall: 0.7530 - val_loss: 0.4874 - val_accuracy: 0.7369 - val_auc: 0.8326 - val_precision: 0.7324 - val_recall: 0.7464\n",
            "Epoch 268/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4141 - accuracy: 0.7470 - auc: 0.8461 - precision: 0.7449 - recall: 0.7519 - val_loss: 0.4871 - val_accuracy: 0.7390 - val_auc: 0.8324 - val_precision: 0.7416 - val_recall: 0.7333\n",
            "Epoch 269/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4137 - accuracy: 0.7478 - auc: 0.8467 - precision: 0.7449 - recall: 0.7542 - val_loss: 0.4864 - val_accuracy: 0.7363 - val_auc: 0.8325 - val_precision: 0.7358 - val_recall: 0.7372\n",
            "Epoch 270/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4145 - accuracy: 0.7477 - auc: 0.8466 - precision: 0.7466 - recall: 0.7505 - val_loss: 0.4877 - val_accuracy: 0.7386 - val_auc: 0.8321 - val_precision: 0.7400 - val_recall: 0.7356\n",
            "Epoch 271/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4147 - accuracy: 0.7476 - auc: 0.8460 - precision: 0.7467 - recall: 0.7501 - val_loss: 0.4861 - val_accuracy: 0.7388 - val_auc: 0.8320 - val_precision: 0.7430 - val_recall: 0.7301\n",
            "Epoch 272/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4148 - accuracy: 0.7473 - auc: 0.8460 - precision: 0.7466 - recall: 0.7493 - val_loss: 0.4864 - val_accuracy: 0.7358 - val_auc: 0.8320 - val_precision: 0.7347 - val_recall: 0.7380\n",
            "Epoch 273/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4145 - accuracy: 0.7485 - auc: 0.8465 - precision: 0.7470 - recall: 0.7520 - val_loss: 0.4859 - val_accuracy: 0.7378 - val_auc: 0.8325 - val_precision: 0.7363 - val_recall: 0.7409\n",
            "Epoch 274/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4143 - accuracy: 0.7476 - auc: 0.8461 - precision: 0.7482 - recall: 0.7469 - val_loss: 0.4862 - val_accuracy: 0.7394 - val_auc: 0.8328 - val_precision: 0.7390 - val_recall: 0.7401\n",
            "Epoch 275/500\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.4148 - accuracy: 0.7477 - auc: 0.8459 - precision: 0.7486 - recall: 0.7466 - val_loss: 0.4859 - val_accuracy: 0.7392 - val_auc: 0.8320 - val_precision: 0.7429 - val_recall: 0.7317\n",
            "Epoch 276/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4147 - accuracy: 0.7481 - auc: 0.8466 - precision: 0.7488 - recall: 0.7472 - val_loss: 0.4863 - val_accuracy: 0.7386 - val_auc: 0.8321 - val_precision: 0.7397 - val_recall: 0.7361\n",
            "Epoch 277/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4140 - accuracy: 0.7472 - auc: 0.8466 - precision: 0.7469 - recall: 0.7483 - val_loss: 0.4854 - val_accuracy: 0.7391 - val_auc: 0.8328 - val_precision: 0.7431 - val_recall: 0.7308\n",
            "Epoch 278/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4142 - accuracy: 0.7471 - auc: 0.8466 - precision: 0.7455 - recall: 0.7509 - val_loss: 0.4860 - val_accuracy: 0.7370 - val_auc: 0.8328 - val_precision: 0.7393 - val_recall: 0.7323\n",
            "Epoch 279/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4140 - accuracy: 0.7481 - auc: 0.8468 - precision: 0.7499 - recall: 0.7450 - val_loss: 0.4846 - val_accuracy: 0.7386 - val_auc: 0.8329 - val_precision: 0.7399 - val_recall: 0.7356\n",
            "Epoch 280/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4140 - accuracy: 0.7466 - auc: 0.8462 - precision: 0.7460 - recall: 0.7485 - val_loss: 0.4857 - val_accuracy: 0.7384 - val_auc: 0.8326 - val_precision: 0.7408 - val_recall: 0.7333\n",
            "Epoch 281/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4141 - accuracy: 0.7469 - auc: 0.8463 - precision: 0.7453 - recall: 0.7508 - val_loss: 0.4855 - val_accuracy: 0.7374 - val_auc: 0.8326 - val_precision: 0.7365 - val_recall: 0.7391\n",
            "Epoch 282/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4142 - accuracy: 0.7489 - auc: 0.8466 - precision: 0.7502 - recall: 0.7468 - val_loss: 0.4855 - val_accuracy: 0.7409 - val_auc: 0.8322 - val_precision: 0.7508 - val_recall: 0.7210\n",
            "Epoch 283/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4139 - accuracy: 0.7478 - auc: 0.8466 - precision: 0.7481 - recall: 0.7476 - val_loss: 0.4863 - val_accuracy: 0.7374 - val_auc: 0.8324 - val_precision: 0.7388 - val_recall: 0.7343\n",
            "Epoch 284/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4132 - accuracy: 0.7486 - auc: 0.8475 - precision: 0.7479 - recall: 0.7504 - val_loss: 0.4860 - val_accuracy: 0.7383 - val_auc: 0.8326 - val_precision: 0.7400 - val_recall: 0.7347\n",
            "Epoch 285/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4148 - accuracy: 0.7472 - auc: 0.8461 - precision: 0.7453 - recall: 0.7515 - val_loss: 0.4852 - val_accuracy: 0.7378 - val_auc: 0.8327 - val_precision: 0.7388 - val_recall: 0.7358\n",
            "Epoch 286/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4138 - accuracy: 0.7478 - auc: 0.8466 - precision: 0.7472 - recall: 0.7496 - val_loss: 0.4857 - val_accuracy: 0.7378 - val_auc: 0.8328 - val_precision: 0.7369 - val_recall: 0.7396\n",
            "Epoch 287/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4140 - accuracy: 0.7469 - auc: 0.8465 - precision: 0.7452 - recall: 0.7508 - val_loss: 0.4859 - val_accuracy: 0.7377 - val_auc: 0.8328 - val_precision: 0.7360 - val_recall: 0.7411\n",
            "Epoch 288/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4141 - accuracy: 0.7476 - auc: 0.8472 - precision: 0.7457 - recall: 0.7522 - val_loss: 0.4859 - val_accuracy: 0.7377 - val_auc: 0.8324 - val_precision: 0.7382 - val_recall: 0.7365\n",
            "Epoch 289/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4141 - accuracy: 0.7471 - auc: 0.8467 - precision: 0.7449 - recall: 0.7522 - val_loss: 0.4864 - val_accuracy: 0.7364 - val_auc: 0.8326 - val_precision: 0.7305 - val_recall: 0.7490\n",
            "Epoch 290/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4137 - accuracy: 0.7482 - auc: 0.8470 - precision: 0.7461 - recall: 0.7531 - val_loss: 0.4859 - val_accuracy: 0.7384 - val_auc: 0.8326 - val_precision: 0.7388 - val_recall: 0.7374\n",
            "Epoch 291/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4138 - accuracy: 0.7480 - auc: 0.8466 - precision: 0.7466 - recall: 0.7511 - val_loss: 0.4863 - val_accuracy: 0.7372 - val_auc: 0.8321 - val_precision: 0.7312 - val_recall: 0.7502\n",
            "Epoch 292/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4140 - accuracy: 0.7471 - auc: 0.8468 - precision: 0.7436 - recall: 0.7548 - val_loss: 0.4855 - val_accuracy: 0.7378 - val_auc: 0.8325 - val_precision: 0.7372 - val_recall: 0.7388\n",
            "Epoch 293/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4135 - accuracy: 0.7491 - auc: 0.8472 - precision: 0.7470 - recall: 0.7539 - val_loss: 0.4868 - val_accuracy: 0.7373 - val_auc: 0.8322 - val_precision: 0.7356 - val_recall: 0.7406\n",
            "Epoch 294/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4140 - accuracy: 0.7458 - auc: 0.8461 - precision: 0.7430 - recall: 0.7521 - val_loss: 0.4862 - val_accuracy: 0.7368 - val_auc: 0.8328 - val_precision: 0.7317 - val_recall: 0.7476\n",
            "Epoch 295/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4144 - accuracy: 0.7474 - auc: 0.8464 - precision: 0.7446 - recall: 0.7538 - val_loss: 0.4871 - val_accuracy: 0.7356 - val_auc: 0.8327 - val_precision: 0.7280 - val_recall: 0.7522\n",
            "Epoch 296/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4137 - accuracy: 0.7485 - auc: 0.8471 - precision: 0.7456 - recall: 0.7551 - val_loss: 0.4848 - val_accuracy: 0.7380 - val_auc: 0.8327 - val_precision: 0.7392 - val_recall: 0.7354\n",
            "Epoch 297/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4132 - accuracy: 0.7475 - auc: 0.8467 - precision: 0.7470 - recall: 0.7490 - val_loss: 0.4868 - val_accuracy: 0.7377 - val_auc: 0.8324 - val_precision: 0.7374 - val_recall: 0.7382\n",
            "Epoch 298/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4133 - accuracy: 0.7474 - auc: 0.8470 - precision: 0.7455 - recall: 0.7516 - val_loss: 0.4856 - val_accuracy: 0.7396 - val_auc: 0.8323 - val_precision: 0.7448 - val_recall: 0.7289\n",
            "Epoch 299/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4137 - accuracy: 0.7484 - auc: 0.8471 - precision: 0.7476 - recall: 0.7504 - val_loss: 0.4860 - val_accuracy: 0.7365 - val_auc: 0.8324 - val_precision: 0.7349 - val_recall: 0.7399\n",
            "Epoch 300/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4131 - accuracy: 0.7476 - auc: 0.8470 - precision: 0.7448 - recall: 0.7538 - val_loss: 0.4860 - val_accuracy: 0.7381 - val_auc: 0.8331 - val_precision: 0.7389 - val_recall: 0.7363\n",
            "Epoch 301/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4138 - accuracy: 0.7480 - auc: 0.8468 - precision: 0.7470 - recall: 0.7506 - val_loss: 0.4852 - val_accuracy: 0.7378 - val_auc: 0.8329 - val_precision: 0.7395 - val_recall: 0.7340\n",
            "Epoch 302/500\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.4136 - accuracy: 0.7469 - auc: 0.8466 - precision: 0.7441 - recall: 0.7533 - val_loss: 0.4867 - val_accuracy: 0.7375 - val_auc: 0.8330 - val_precision: 0.7341 - val_recall: 0.7446\n",
            "Epoch 303/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4125 - accuracy: 0.7479 - auc: 0.8476 - precision: 0.7460 - recall: 0.7522 - val_loss: 0.4848 - val_accuracy: 0.7389 - val_auc: 0.8330 - val_precision: 0.7402 - val_recall: 0.7361\n",
            "Epoch 304/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4135 - accuracy: 0.7480 - auc: 0.8472 - precision: 0.7472 - recall: 0.7503 - val_loss: 0.4858 - val_accuracy: 0.7361 - val_auc: 0.8327 - val_precision: 0.7294 - val_recall: 0.7504\n",
            "Epoch 305/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4128 - accuracy: 0.7475 - auc: 0.8475 - precision: 0.7459 - recall: 0.7514 - val_loss: 0.4854 - val_accuracy: 0.7379 - val_auc: 0.8327 - val_precision: 0.7348 - val_recall: 0.7443\n",
            "Epoch 306/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4136 - accuracy: 0.7487 - auc: 0.8469 - precision: 0.7469 - recall: 0.7528 - val_loss: 0.4853 - val_accuracy: 0.7375 - val_auc: 0.8329 - val_precision: 0.7339 - val_recall: 0.7451\n",
            "Epoch 307/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4139 - accuracy: 0.7476 - auc: 0.8469 - precision: 0.7437 - recall: 0.7561 - val_loss: 0.4872 - val_accuracy: 0.7377 - val_auc: 0.8327 - val_precision: 0.7355 - val_recall: 0.7423\n",
            "Epoch 308/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4140 - accuracy: 0.7484 - auc: 0.8465 - precision: 0.7458 - recall: 0.7543 - val_loss: 0.4860 - val_accuracy: 0.7387 - val_auc: 0.8327 - val_precision: 0.7375 - val_recall: 0.7410\n",
            "Epoch 309/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4132 - accuracy: 0.7478 - auc: 0.8473 - precision: 0.7471 - recall: 0.7497 - val_loss: 0.4858 - val_accuracy: 0.7388 - val_auc: 0.8330 - val_precision: 0.7393 - val_recall: 0.7377\n",
            "Epoch 310/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4131 - accuracy: 0.7483 - auc: 0.8476 - precision: 0.7476 - recall: 0.7502 - val_loss: 0.4871 - val_accuracy: 0.7374 - val_auc: 0.8324 - val_precision: 0.7339 - val_recall: 0.7447\n",
            "Epoch 311/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4129 - accuracy: 0.7487 - auc: 0.8474 - precision: 0.7468 - recall: 0.7530 - val_loss: 0.4857 - val_accuracy: 0.7373 - val_auc: 0.8327 - val_precision: 0.7351 - val_recall: 0.7419\n",
            "Epoch 312/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4134 - accuracy: 0.7484 - auc: 0.8470 - precision: 0.7479 - recall: 0.7499 - val_loss: 0.4854 - val_accuracy: 0.7382 - val_auc: 0.8334 - val_precision: 0.7329 - val_recall: 0.7495\n",
            "Epoch 313/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4121 - accuracy: 0.7478 - auc: 0.8481 - precision: 0.7448 - recall: 0.7543 - val_loss: 0.4870 - val_accuracy: 0.7374 - val_auc: 0.8326 - val_precision: 0.7354 - val_recall: 0.7415\n",
            "Epoch 314/500\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.4133 - accuracy: 0.7483 - auc: 0.8470 - precision: 0.7480 - recall: 0.7495 - val_loss: 0.4869 - val_accuracy: 0.7381 - val_auc: 0.8328 - val_precision: 0.7380 - val_recall: 0.7383\n",
            "Epoch 315/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4125 - accuracy: 0.7488 - auc: 0.8475 - precision: 0.7479 - recall: 0.7510 - val_loss: 0.4872 - val_accuracy: 0.7387 - val_auc: 0.8329 - val_precision: 0.7391 - val_recall: 0.7376\n",
            "Epoch 316/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4124 - accuracy: 0.7481 - auc: 0.8477 - precision: 0.7478 - recall: 0.7494 - val_loss: 0.4860 - val_accuracy: 0.7399 - val_auc: 0.8328 - val_precision: 0.7437 - val_recall: 0.7320\n",
            "Epoch 317/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4135 - accuracy: 0.7480 - auc: 0.8468 - precision: 0.7475 - recall: 0.7497 - val_loss: 0.4854 - val_accuracy: 0.7382 - val_auc: 0.8328 - val_precision: 0.7401 - val_recall: 0.7341\n",
            "Epoch 318/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4139 - accuracy: 0.7475 - auc: 0.8464 - precision: 0.7454 - recall: 0.7523 - val_loss: 0.4848 - val_accuracy: 0.7380 - val_auc: 0.8330 - val_precision: 0.7392 - val_recall: 0.7353\n",
            "Epoch 319/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4129 - accuracy: 0.7490 - auc: 0.8474 - precision: 0.7496 - recall: 0.7485 - val_loss: 0.4869 - val_accuracy: 0.7380 - val_auc: 0.8331 - val_precision: 0.7370 - val_recall: 0.7401\n",
            "Epoch 320/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4130 - accuracy: 0.7485 - auc: 0.8472 - precision: 0.7461 - recall: 0.7537 - val_loss: 0.4849 - val_accuracy: 0.7383 - val_auc: 0.8329 - val_precision: 0.7392 - val_recall: 0.7364\n",
            "Epoch 321/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4132 - accuracy: 0.7484 - auc: 0.8470 - precision: 0.7476 - recall: 0.7506 - val_loss: 0.4861 - val_accuracy: 0.7379 - val_auc: 0.8329 - val_precision: 0.7369 - val_recall: 0.7397\n",
            "Epoch 322/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4128 - accuracy: 0.7492 - auc: 0.8477 - precision: 0.7465 - recall: 0.7552 - val_loss: 0.4850 - val_accuracy: 0.7388 - val_auc: 0.8331 - val_precision: 0.7399 - val_recall: 0.7363\n",
            "Epoch 323/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4129 - accuracy: 0.7498 - auc: 0.8474 - precision: 0.7496 - recall: 0.7506 - val_loss: 0.4869 - val_accuracy: 0.7401 - val_auc: 0.8333 - val_precision: 0.7445 - val_recall: 0.7308\n",
            "Epoch 324/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4131 - accuracy: 0.7484 - auc: 0.8468 - precision: 0.7468 - recall: 0.7521 - val_loss: 0.4865 - val_accuracy: 0.7399 - val_auc: 0.8328 - val_precision: 0.7448 - val_recall: 0.7296\n",
            "Epoch 325/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4128 - accuracy: 0.7491 - auc: 0.8475 - precision: 0.7481 - recall: 0.7517 - val_loss: 0.4860 - val_accuracy: 0.7393 - val_auc: 0.8327 - val_precision: 0.7423 - val_recall: 0.7329\n",
            "Epoch 326/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4128 - accuracy: 0.7485 - auc: 0.8474 - precision: 0.7469 - recall: 0.7522 - val_loss: 0.4847 - val_accuracy: 0.7386 - val_auc: 0.8333 - val_precision: 0.7394 - val_recall: 0.7369\n",
            "Epoch 327/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4130 - accuracy: 0.7495 - auc: 0.8476 - precision: 0.7481 - recall: 0.7527 - val_loss: 0.4852 - val_accuracy: 0.7380 - val_auc: 0.8333 - val_precision: 0.7350 - val_recall: 0.7444\n",
            "Epoch 328/500\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.4136 - accuracy: 0.7478 - auc: 0.8475 - precision: 0.7435 - recall: 0.7570 - val_loss: 0.4856 - val_accuracy: 0.7402 - val_auc: 0.8328 - val_precision: 0.7431 - val_recall: 0.7340\n",
            "Epoch 329/500\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.4133 - accuracy: 0.7482 - auc: 0.8473 - precision: 0.7466 - recall: 0.7518 - val_loss: 0.4853 - val_accuracy: 0.7400 - val_auc: 0.8335 - val_precision: 0.7389 - val_recall: 0.7421\n",
            "Epoch 330/500\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.4126 - accuracy: 0.7478 - auc: 0.8473 - precision: 0.7455 - recall: 0.7530 - val_loss: 0.4856 - val_accuracy: 0.7401 - val_auc: 0.8329 - val_precision: 0.7457 - val_recall: 0.7288\n",
            "Epoch 331/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4122 - accuracy: 0.7499 - auc: 0.8478 - precision: 0.7500 - recall: 0.7503 - val_loss: 0.4848 - val_accuracy: 0.7398 - val_auc: 0.8334 - val_precision: 0.7455 - val_recall: 0.7281\n",
            "Epoch 332/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4122 - accuracy: 0.7488 - auc: 0.8479 - precision: 0.7470 - recall: 0.7528 - val_loss: 0.4845 - val_accuracy: 0.7386 - val_auc: 0.8328 - val_precision: 0.7419 - val_recall: 0.7318\n",
            "Epoch 333/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4129 - accuracy: 0.7491 - auc: 0.8472 - precision: 0.7478 - recall: 0.7522 - val_loss: 0.4848 - val_accuracy: 0.7393 - val_auc: 0.8331 - val_precision: 0.7415 - val_recall: 0.7346\n",
            "Epoch 334/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4138 - accuracy: 0.7493 - auc: 0.8470 - precision: 0.7489 - recall: 0.7506 - val_loss: 0.4857 - val_accuracy: 0.7394 - val_auc: 0.8330 - val_precision: 0.7434 - val_recall: 0.7310\n",
            "Epoch 335/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4122 - accuracy: 0.7495 - auc: 0.8476 - precision: 0.7499 - recall: 0.7491 - val_loss: 0.4848 - val_accuracy: 0.7400 - val_auc: 0.8333 - val_precision: 0.7429 - val_recall: 0.7340\n",
            "Epoch 336/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4129 - accuracy: 0.7493 - auc: 0.8474 - precision: 0.7469 - recall: 0.7545 - val_loss: 0.4848 - val_accuracy: 0.7399 - val_auc: 0.8331 - val_precision: 0.7422 - val_recall: 0.7349\n",
            "Epoch 337/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4125 - accuracy: 0.7488 - auc: 0.8479 - precision: 0.7484 - recall: 0.7501 - val_loss: 0.4868 - val_accuracy: 0.7368 - val_auc: 0.8329 - val_precision: 0.7323 - val_recall: 0.7463\n",
            "Epoch 338/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4126 - accuracy: 0.7490 - auc: 0.8475 - precision: 0.7471 - recall: 0.7532 - val_loss: 0.4858 - val_accuracy: 0.7398 - val_auc: 0.8329 - val_precision: 0.7419 - val_recall: 0.7352\n",
            "Epoch 339/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4125 - accuracy: 0.7473 - auc: 0.8471 - precision: 0.7463 - recall: 0.7499 - val_loss: 0.4848 - val_accuracy: 0.7396 - val_auc: 0.8335 - val_precision: 0.7413 - val_recall: 0.7361\n",
            "Epoch 340/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4124 - accuracy: 0.7496 - auc: 0.8482 - precision: 0.7475 - recall: 0.7545 - val_loss: 0.4842 - val_accuracy: 0.7380 - val_auc: 0.8335 - val_precision: 0.7356 - val_recall: 0.7430\n",
            "Epoch 341/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4124 - accuracy: 0.7498 - auc: 0.8481 - precision: 0.7476 - recall: 0.7548 - val_loss: 0.4857 - val_accuracy: 0.7381 - val_auc: 0.8332 - val_precision: 0.7378 - val_recall: 0.7384\n",
            "Epoch 342/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4120 - accuracy: 0.7501 - auc: 0.8483 - precision: 0.7491 - recall: 0.7528 - val_loss: 0.4860 - val_accuracy: 0.7376 - val_auc: 0.8333 - val_precision: 0.7343 - val_recall: 0.7443\n",
            "Epoch 343/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4113 - accuracy: 0.7494 - auc: 0.8485 - precision: 0.7471 - recall: 0.7547 - val_loss: 0.4855 - val_accuracy: 0.7386 - val_auc: 0.8334 - val_precision: 0.7388 - val_recall: 0.7380\n",
            "Epoch 344/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4114 - accuracy: 0.7491 - auc: 0.8484 - precision: 0.7477 - recall: 0.7526 - val_loss: 0.4855 - val_accuracy: 0.7390 - val_auc: 0.8341 - val_precision: 0.7364 - val_recall: 0.7444\n",
            "Epoch 345/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4125 - accuracy: 0.7484 - auc: 0.8475 - precision: 0.7454 - recall: 0.7549 - val_loss: 0.4851 - val_accuracy: 0.7395 - val_auc: 0.8334 - val_precision: 0.7414 - val_recall: 0.7355\n",
            "Epoch 346/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4122 - accuracy: 0.7486 - auc: 0.8482 - precision: 0.7479 - recall: 0.7504 - val_loss: 0.4854 - val_accuracy: 0.7385 - val_auc: 0.8334 - val_precision: 0.7376 - val_recall: 0.7404\n",
            "Epoch 347/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4121 - accuracy: 0.7489 - auc: 0.8482 - precision: 0.7477 - recall: 0.7519 - val_loss: 0.4857 - val_accuracy: 0.7388 - val_auc: 0.8333 - val_precision: 0.7401 - val_recall: 0.7359\n",
            "Epoch 348/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4116 - accuracy: 0.7493 - auc: 0.8482 - precision: 0.7489 - recall: 0.7505 - val_loss: 0.4870 - val_accuracy: 0.7381 - val_auc: 0.8333 - val_precision: 0.7337 - val_recall: 0.7474\n",
            "Epoch 349/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4127 - accuracy: 0.7486 - auc: 0.8475 - precision: 0.7459 - recall: 0.7548 - val_loss: 0.4858 - val_accuracy: 0.7389 - val_auc: 0.8330 - val_precision: 0.7360 - val_recall: 0.7448\n",
            "Epoch 350/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4122 - accuracy: 0.7498 - auc: 0.8482 - precision: 0.7468 - recall: 0.7563 - val_loss: 0.4854 - val_accuracy: 0.7402 - val_auc: 0.8332 - val_precision: 0.7418 - val_recall: 0.7368\n",
            "Epoch 351/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4121 - accuracy: 0.7494 - auc: 0.8479 - precision: 0.7494 - recall: 0.7498 - val_loss: 0.4840 - val_accuracy: 0.7386 - val_auc: 0.8337 - val_precision: 0.7387 - val_recall: 0.7383\n",
            "Epoch 352/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4130 - accuracy: 0.7481 - auc: 0.8474 - precision: 0.7455 - recall: 0.7538 - val_loss: 0.4852 - val_accuracy: 0.7375 - val_auc: 0.8333 - val_precision: 0.7340 - val_recall: 0.7447\n",
            "Epoch 353/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4122 - accuracy: 0.7490 - auc: 0.8477 - precision: 0.7479 - recall: 0.7515 - val_loss: 0.4848 - val_accuracy: 0.7392 - val_auc: 0.8336 - val_precision: 0.7411 - val_recall: 0.7351\n",
            "Epoch 354/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4124 - accuracy: 0.7487 - auc: 0.8477 - precision: 0.7472 - recall: 0.7521 - val_loss: 0.4840 - val_accuracy: 0.7390 - val_auc: 0.8336 - val_precision: 0.7407 - val_recall: 0.7354\n",
            "Epoch 355/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4119 - accuracy: 0.7492 - auc: 0.8480 - precision: 0.7470 - recall: 0.7542 - val_loss: 0.4847 - val_accuracy: 0.7389 - val_auc: 0.8334 - val_precision: 0.7380 - val_recall: 0.7407\n",
            "Epoch 356/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4129 - accuracy: 0.7493 - auc: 0.8474 - precision: 0.7469 - recall: 0.7547 - val_loss: 0.4865 - val_accuracy: 0.7398 - val_auc: 0.8330 - val_precision: 0.7414 - val_recall: 0.7361\n",
            "Epoch 357/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4122 - accuracy: 0.7495 - auc: 0.8479 - precision: 0.7500 - recall: 0.7490 - val_loss: 0.4871 - val_accuracy: 0.7372 - val_auc: 0.8332 - val_precision: 0.7317 - val_recall: 0.7488\n",
            "Epoch 358/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4121 - accuracy: 0.7486 - auc: 0.8476 - precision: 0.7460 - recall: 0.7543 - val_loss: 0.4854 - val_accuracy: 0.7395 - val_auc: 0.8335 - val_precision: 0.7430 - val_recall: 0.7321\n",
            "Epoch 359/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4121 - accuracy: 0.7484 - auc: 0.8480 - precision: 0.7471 - recall: 0.7514 - val_loss: 0.4855 - val_accuracy: 0.7388 - val_auc: 0.8335 - val_precision: 0.7397 - val_recall: 0.7367\n",
            "Epoch 360/500\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.4115 - accuracy: 0.7497 - auc: 0.8484 - precision: 0.7496 - recall: 0.7505 - val_loss: 0.4865 - val_accuracy: 0.7393 - val_auc: 0.8332 - val_precision: 0.7430 - val_recall: 0.7316\n",
            "Epoch 361/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4119 - accuracy: 0.7492 - auc: 0.8481 - precision: 0.7480 - recall: 0.7521 - val_loss: 0.4856 - val_accuracy: 0.7380 - val_auc: 0.8331 - val_precision: 0.7385 - val_recall: 0.7368\n",
            "Epoch 362/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4123 - accuracy: 0.7500 - auc: 0.8479 - precision: 0.7528 - recall: 0.7448 - val_loss: 0.4869 - val_accuracy: 0.7388 - val_auc: 0.8331 - val_precision: 0.7427 - val_recall: 0.7304\n",
            "Epoch 363/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4114 - accuracy: 0.7487 - auc: 0.8484 - precision: 0.7489 - recall: 0.7489 - val_loss: 0.4854 - val_accuracy: 0.7376 - val_auc: 0.8337 - val_precision: 0.7346 - val_recall: 0.7440\n",
            "Epoch 364/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4118 - accuracy: 0.7498 - auc: 0.8481 - precision: 0.7500 - recall: 0.7498 - val_loss: 0.4860 - val_accuracy: 0.7379 - val_auc: 0.8331 - val_precision: 0.7365 - val_recall: 0.7408\n",
            "Epoch 365/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4114 - accuracy: 0.7492 - auc: 0.8485 - precision: 0.7470 - recall: 0.7543 - val_loss: 0.4861 - val_accuracy: 0.7402 - val_auc: 0.8336 - val_precision: 0.7397 - val_recall: 0.7410\n",
            "Epoch 366/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4108 - accuracy: 0.7495 - auc: 0.8487 - precision: 0.7482 - recall: 0.7526 - val_loss: 0.4854 - val_accuracy: 0.7392 - val_auc: 0.8330 - val_precision: 0.7432 - val_recall: 0.7308\n",
            "Epoch 367/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4116 - accuracy: 0.7499 - auc: 0.8483 - precision: 0.7487 - recall: 0.7528 - val_loss: 0.4848 - val_accuracy: 0.7395 - val_auc: 0.8335 - val_precision: 0.7431 - val_recall: 0.7318\n",
            "Epoch 368/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4122 - accuracy: 0.7510 - auc: 0.8479 - precision: 0.7566 - recall: 0.7406 - val_loss: 0.4855 - val_accuracy: 0.7387 - val_auc: 0.8340 - val_precision: 0.7380 - val_recall: 0.7400\n",
            "Epoch 369/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4120 - accuracy: 0.7500 - auc: 0.8481 - precision: 0.7487 - recall: 0.7530 - val_loss: 0.4852 - val_accuracy: 0.7388 - val_auc: 0.8334 - val_precision: 0.7346 - val_recall: 0.7475\n",
            "Epoch 370/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4114 - accuracy: 0.7488 - auc: 0.8482 - precision: 0.7480 - recall: 0.7511 - val_loss: 0.4856 - val_accuracy: 0.7391 - val_auc: 0.8340 - val_precision: 0.7367 - val_recall: 0.7442\n",
            "Epoch 371/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4106 - accuracy: 0.7502 - auc: 0.8490 - precision: 0.7492 - recall: 0.7529 - val_loss: 0.4854 - val_accuracy: 0.7390 - val_auc: 0.8336 - val_precision: 0.7390 - val_recall: 0.7390\n",
            "Epoch 372/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4117 - accuracy: 0.7489 - auc: 0.8486 - precision: 0.7465 - recall: 0.7544 - val_loss: 0.4853 - val_accuracy: 0.7392 - val_auc: 0.8336 - val_precision: 0.7404 - val_recall: 0.7365\n",
            "Epoch 373/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4111 - accuracy: 0.7506 - auc: 0.8491 - precision: 0.7491 - recall: 0.7540 - val_loss: 0.4859 - val_accuracy: 0.7386 - val_auc: 0.8333 - val_precision: 0.7372 - val_recall: 0.7415\n",
            "Epoch 374/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4122 - accuracy: 0.7487 - auc: 0.8477 - precision: 0.7464 - recall: 0.7539 - val_loss: 0.4869 - val_accuracy: 0.7388 - val_auc: 0.8336 - val_precision: 0.7359 - val_recall: 0.7447\n",
            "Epoch 375/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4118 - accuracy: 0.7492 - auc: 0.8479 - precision: 0.7451 - recall: 0.7581 - val_loss: 0.4867 - val_accuracy: 0.7401 - val_auc: 0.8339 - val_precision: 0.7373 - val_recall: 0.7458\n",
            "Epoch 376/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4118 - accuracy: 0.7498 - auc: 0.8486 - precision: 0.7477 - recall: 0.7545 - val_loss: 0.4872 - val_accuracy: 0.7375 - val_auc: 0.8334 - val_precision: 0.7321 - val_recall: 0.7491\n",
            "Epoch 377/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4122 - accuracy: 0.7496 - auc: 0.8485 - precision: 0.7477 - recall: 0.7542 - val_loss: 0.4861 - val_accuracy: 0.7372 - val_auc: 0.8334 - val_precision: 0.7295 - val_recall: 0.7537\n",
            "Epoch 378/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4119 - accuracy: 0.7490 - auc: 0.8482 - precision: 0.7453 - recall: 0.7571 - val_loss: 0.4877 - val_accuracy: 0.7393 - val_auc: 0.8333 - val_precision: 0.7378 - val_recall: 0.7423\n",
            "Epoch 379/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4119 - accuracy: 0.7495 - auc: 0.8482 - precision: 0.7476 - recall: 0.7539 - val_loss: 0.4865 - val_accuracy: 0.7375 - val_auc: 0.8338 - val_precision: 0.7285 - val_recall: 0.7571\n",
            "Epoch 380/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4113 - accuracy: 0.7497 - auc: 0.8488 - precision: 0.7464 - recall: 0.7570 - val_loss: 0.4867 - val_accuracy: 0.7382 - val_auc: 0.8333 - val_precision: 0.7370 - val_recall: 0.7404\n",
            "Epoch 381/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4112 - accuracy: 0.7494 - auc: 0.8485 - precision: 0.7464 - recall: 0.7562 - val_loss: 0.4870 - val_accuracy: 0.7381 - val_auc: 0.8332 - val_precision: 0.7336 - val_recall: 0.7475\n",
            "Epoch 382/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4126 - accuracy: 0.7470 - auc: 0.8468 - precision: 0.7446 - recall: 0.7526 - val_loss: 0.4871 - val_accuracy: 0.7373 - val_auc: 0.8334 - val_precision: 0.7321 - val_recall: 0.7484\n",
            "Epoch 383/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4118 - accuracy: 0.7491 - auc: 0.8487 - precision: 0.7462 - recall: 0.7554 - val_loss: 0.4866 - val_accuracy: 0.7386 - val_auc: 0.8339 - val_precision: 0.7358 - val_recall: 0.7442\n",
            "Epoch 384/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4118 - accuracy: 0.7484 - auc: 0.8479 - precision: 0.7457 - recall: 0.7545 - val_loss: 0.4853 - val_accuracy: 0.7394 - val_auc: 0.8344 - val_precision: 0.7354 - val_recall: 0.7478\n",
            "Epoch 385/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4108 - accuracy: 0.7497 - auc: 0.8493 - precision: 0.7460 - recall: 0.7578 - val_loss: 0.4864 - val_accuracy: 0.7376 - val_auc: 0.8339 - val_precision: 0.7325 - val_recall: 0.7484\n",
            "Epoch 386/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4111 - accuracy: 0.7481 - auc: 0.8484 - precision: 0.7455 - recall: 0.7539 - val_loss: 0.4847 - val_accuracy: 0.7386 - val_auc: 0.8339 - val_precision: 0.7381 - val_recall: 0.7394\n",
            "Epoch 387/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4111 - accuracy: 0.7488 - auc: 0.8488 - precision: 0.7461 - recall: 0.7548 - val_loss: 0.4856 - val_accuracy: 0.7390 - val_auc: 0.8338 - val_precision: 0.7365 - val_recall: 0.7442\n",
            "Epoch 388/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4107 - accuracy: 0.7497 - auc: 0.8490 - precision: 0.7465 - recall: 0.7567 - val_loss: 0.4851 - val_accuracy: 0.7396 - val_auc: 0.8342 - val_precision: 0.7391 - val_recall: 0.7403\n",
            "Epoch 389/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4114 - accuracy: 0.7500 - auc: 0.8480 - precision: 0.7498 - recall: 0.7510 - val_loss: 0.4852 - val_accuracy: 0.7399 - val_auc: 0.8337 - val_precision: 0.7453 - val_recall: 0.7287\n",
            "Epoch 390/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4119 - accuracy: 0.7486 - auc: 0.8482 - precision: 0.7470 - recall: 0.7525 - val_loss: 0.4864 - val_accuracy: 0.7403 - val_auc: 0.8342 - val_precision: 0.7455 - val_recall: 0.7295\n",
            "Epoch 391/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4121 - accuracy: 0.7500 - auc: 0.8483 - precision: 0.7499 - recall: 0.7509 - val_loss: 0.4848 - val_accuracy: 0.7392 - val_auc: 0.8337 - val_precision: 0.7386 - val_recall: 0.7404\n",
            "Epoch 392/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4109 - accuracy: 0.7499 - auc: 0.8490 - precision: 0.7489 - recall: 0.7524 - val_loss: 0.4846 - val_accuracy: 0.7378 - val_auc: 0.8339 - val_precision: 0.7361 - val_recall: 0.7413\n",
            "Epoch 393/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4109 - accuracy: 0.7503 - auc: 0.8490 - precision: 0.7488 - recall: 0.7539 - val_loss: 0.4842 - val_accuracy: 0.7394 - val_auc: 0.8338 - val_precision: 0.7412 - val_recall: 0.7356\n",
            "Epoch 394/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4112 - accuracy: 0.7490 - auc: 0.8486 - precision: 0.7465 - recall: 0.7545 - val_loss: 0.4849 - val_accuracy: 0.7386 - val_auc: 0.8335 - val_precision: 0.7394 - val_recall: 0.7368\n",
            "Epoch 395/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4107 - accuracy: 0.7498 - auc: 0.8491 - precision: 0.7492 - recall: 0.7515 - val_loss: 0.4845 - val_accuracy: 0.7393 - val_auc: 0.8336 - val_precision: 0.7398 - val_recall: 0.7380\n",
            "Epoch 396/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4113 - accuracy: 0.7492 - auc: 0.8486 - precision: 0.7472 - recall: 0.7537 - val_loss: 0.4852 - val_accuracy: 0.7399 - val_auc: 0.8337 - val_precision: 0.7421 - val_recall: 0.7353\n",
            "Epoch 397/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4108 - accuracy: 0.7508 - auc: 0.8492 - precision: 0.7501 - recall: 0.7527 - val_loss: 0.4852 - val_accuracy: 0.7391 - val_auc: 0.8333 - val_precision: 0.7403 - val_recall: 0.7366\n",
            "Epoch 398/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4107 - accuracy: 0.7484 - auc: 0.8485 - precision: 0.7468 - recall: 0.7520 - val_loss: 0.4851 - val_accuracy: 0.7382 - val_auc: 0.8341 - val_precision: 0.7357 - val_recall: 0.7432\n",
            "Epoch 399/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4108 - accuracy: 0.7496 - auc: 0.8490 - precision: 0.7473 - recall: 0.7548 - val_loss: 0.4841 - val_accuracy: 0.7402 - val_auc: 0.8341 - val_precision: 0.7417 - val_recall: 0.7371\n",
            "Epoch 400/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4108 - accuracy: 0.7511 - auc: 0.8494 - precision: 0.7506 - recall: 0.7526 - val_loss: 0.4844 - val_accuracy: 0.7396 - val_auc: 0.8337 - val_precision: 0.7442 - val_recall: 0.7300\n",
            "Epoch 401/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4116 - accuracy: 0.7498 - auc: 0.8484 - precision: 0.7522 - recall: 0.7455 - val_loss: 0.4841 - val_accuracy: 0.7400 - val_auc: 0.8337 - val_precision: 0.7448 - val_recall: 0.7301\n",
            "Epoch 402/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4106 - accuracy: 0.7502 - auc: 0.8487 - precision: 0.7533 - recall: 0.7447 - val_loss: 0.4847 - val_accuracy: 0.7408 - val_auc: 0.8338 - val_precision: 0.7459 - val_recall: 0.7301\n",
            "Epoch 403/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4105 - accuracy: 0.7504 - auc: 0.8490 - precision: 0.7505 - recall: 0.7507 - val_loss: 0.4864 - val_accuracy: 0.7394 - val_auc: 0.8337 - val_precision: 0.7410 - val_recall: 0.7357\n",
            "Epoch 404/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4111 - accuracy: 0.7499 - auc: 0.8485 - precision: 0.7505 - recall: 0.7493 - val_loss: 0.4867 - val_accuracy: 0.7388 - val_auc: 0.8339 - val_precision: 0.7368 - val_recall: 0.7429\n",
            "Epoch 405/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4109 - accuracy: 0.7507 - auc: 0.8488 - precision: 0.7483 - recall: 0.7561 - val_loss: 0.4869 - val_accuracy: 0.7393 - val_auc: 0.8343 - val_precision: 0.7404 - val_recall: 0.7369\n",
            "Epoch 406/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4114 - accuracy: 0.7496 - auc: 0.8487 - precision: 0.7487 - recall: 0.7521 - val_loss: 0.4864 - val_accuracy: 0.7398 - val_auc: 0.8339 - val_precision: 0.7397 - val_recall: 0.7397\n",
            "Epoch 407/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4106 - accuracy: 0.7491 - auc: 0.8485 - precision: 0.7495 - recall: 0.7489 - val_loss: 0.4870 - val_accuracy: 0.7379 - val_auc: 0.8338 - val_precision: 0.7349 - val_recall: 0.7441\n",
            "Epoch 408/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4106 - accuracy: 0.7496 - auc: 0.8489 - precision: 0.7477 - recall: 0.7540 - val_loss: 0.4873 - val_accuracy: 0.7386 - val_auc: 0.8336 - val_precision: 0.7392 - val_recall: 0.7371\n",
            "Epoch 409/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4107 - accuracy: 0.7490 - auc: 0.8488 - precision: 0.7474 - recall: 0.7529 - val_loss: 0.4854 - val_accuracy: 0.7390 - val_auc: 0.8335 - val_precision: 0.7396 - val_recall: 0.7375\n",
            "Epoch 410/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4107 - accuracy: 0.7506 - auc: 0.8492 - precision: 0.7520 - recall: 0.7484 - val_loss: 0.4868 - val_accuracy: 0.7386 - val_auc: 0.8334 - val_precision: 0.7394 - val_recall: 0.7369\n",
            "Epoch 411/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4101 - accuracy: 0.7502 - auc: 0.8490 - precision: 0.7498 - recall: 0.7514 - val_loss: 0.4883 - val_accuracy: 0.7378 - val_auc: 0.8337 - val_precision: 0.7342 - val_recall: 0.7454\n",
            "Epoch 412/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4107 - accuracy: 0.7500 - auc: 0.8490 - precision: 0.7492 - recall: 0.7523 - val_loss: 0.4881 - val_accuracy: 0.7376 - val_auc: 0.8334 - val_precision: 0.7333 - val_recall: 0.7467\n",
            "Epoch 413/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4109 - accuracy: 0.7505 - auc: 0.8490 - precision: 0.7490 - recall: 0.7541 - val_loss: 0.4869 - val_accuracy: 0.7382 - val_auc: 0.8334 - val_precision: 0.7369 - val_recall: 0.7408\n",
            "Epoch 414/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4107 - accuracy: 0.7492 - auc: 0.8487 - precision: 0.7473 - recall: 0.7536 - val_loss: 0.4861 - val_accuracy: 0.7380 - val_auc: 0.8334 - val_precision: 0.7362 - val_recall: 0.7417\n",
            "Epoch 415/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4114 - accuracy: 0.7498 - auc: 0.8481 - precision: 0.7489 - recall: 0.7520 - val_loss: 0.4862 - val_accuracy: 0.7372 - val_auc: 0.8336 - val_precision: 0.7336 - val_recall: 0.7447\n",
            "Epoch 416/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4110 - accuracy: 0.7493 - auc: 0.8485 - precision: 0.7483 - recall: 0.7519 - val_loss: 0.4872 - val_accuracy: 0.7384 - val_auc: 0.8338 - val_precision: 0.7391 - val_recall: 0.7369\n",
            "Epoch 417/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4111 - accuracy: 0.7501 - auc: 0.8484 - precision: 0.7504 - recall: 0.7501 - val_loss: 0.4865 - val_accuracy: 0.7403 - val_auc: 0.8336 - val_precision: 0.7440 - val_recall: 0.7328\n",
            "Epoch 418/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4101 - accuracy: 0.7509 - auc: 0.8492 - precision: 0.7523 - recall: 0.7485 - val_loss: 0.4861 - val_accuracy: 0.7409 - val_auc: 0.8337 - val_precision: 0.7398 - val_recall: 0.7430\n",
            "Epoch 419/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4109 - accuracy: 0.7500 - auc: 0.8485 - precision: 0.7528 - recall: 0.7449 - val_loss: 0.4857 - val_accuracy: 0.7429 - val_auc: 0.8338 - val_precision: 0.7551 - val_recall: 0.7189\n",
            "Epoch 420/500\n",
            "205/205 [==============================] - 4s 18ms/step - loss: 0.4114 - accuracy: 0.7503 - auc: 0.8482 - precision: 0.7538 - recall: 0.7440 - val_loss: 0.4868 - val_accuracy: 0.7427 - val_auc: 0.8341 - val_precision: 0.7530 - val_recall: 0.7221\n",
            "Epoch 421/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4111 - accuracy: 0.7499 - auc: 0.8489 - precision: 0.7498 - recall: 0.7507 - val_loss: 0.4842 - val_accuracy: 0.7401 - val_auc: 0.8337 - val_precision: 0.7497 - val_recall: 0.7209\n",
            "Epoch 422/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4101 - accuracy: 0.7513 - auc: 0.8494 - precision: 0.7518 - recall: 0.7508 - val_loss: 0.4856 - val_accuracy: 0.7409 - val_auc: 0.8336 - val_precision: 0.7518 - val_recall: 0.7192\n",
            "Epoch 423/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4098 - accuracy: 0.7509 - auc: 0.8502 - precision: 0.7508 - recall: 0.7516 - val_loss: 0.4857 - val_accuracy: 0.7389 - val_auc: 0.8337 - val_precision: 0.7417 - val_recall: 0.7329\n",
            "Epoch 424/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4103 - accuracy: 0.7514 - auc: 0.8490 - precision: 0.7552 - recall: 0.7443 - val_loss: 0.4854 - val_accuracy: 0.7381 - val_auc: 0.8341 - val_precision: 0.7356 - val_recall: 0.7433\n",
            "Epoch 425/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4102 - accuracy: 0.7514 - auc: 0.8494 - precision: 0.7525 - recall: 0.7497 - val_loss: 0.4854 - val_accuracy: 0.7396 - val_auc: 0.8339 - val_precision: 0.7437 - val_recall: 0.7311\n",
            "Epoch 426/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4109 - accuracy: 0.7491 - auc: 0.8486 - precision: 0.7483 - recall: 0.7514 - val_loss: 0.4867 - val_accuracy: 0.7400 - val_auc: 0.8336 - val_precision: 0.7419 - val_recall: 0.7361\n",
            "Epoch 427/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4108 - accuracy: 0.7495 - auc: 0.8487 - precision: 0.7482 - recall: 0.7527 - val_loss: 0.4856 - val_accuracy: 0.7401 - val_auc: 0.8337 - val_precision: 0.7433 - val_recall: 0.7335\n",
            "Epoch 428/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4098 - accuracy: 0.7512 - auc: 0.8494 - precision: 0.7531 - recall: 0.7479 - val_loss: 0.4866 - val_accuracy: 0.7407 - val_auc: 0.8338 - val_precision: 0.7433 - val_recall: 0.7353\n",
            "Epoch 429/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4112 - accuracy: 0.7504 - auc: 0.8481 - precision: 0.7569 - recall: 0.7384 - val_loss: 0.4857 - val_accuracy: 0.7409 - val_auc: 0.8334 - val_precision: 0.7506 - val_recall: 0.7214\n",
            "Epoch 430/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4099 - accuracy: 0.7503 - auc: 0.8493 - precision: 0.7526 - recall: 0.7463 - val_loss: 0.4860 - val_accuracy: 0.7423 - val_auc: 0.8336 - val_precision: 0.7526 - val_recall: 0.7219\n",
            "Epoch 431/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4105 - accuracy: 0.7514 - auc: 0.8488 - precision: 0.7578 - recall: 0.7395 - val_loss: 0.4869 - val_accuracy: 0.7394 - val_auc: 0.8336 - val_precision: 0.7395 - val_recall: 0.7391\n",
            "Epoch 432/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4103 - accuracy: 0.7524 - auc: 0.8496 - precision: 0.7573 - recall: 0.7433 - val_loss: 0.4861 - val_accuracy: 0.7429 - val_auc: 0.8337 - val_precision: 0.7530 - val_recall: 0.7227\n",
            "Epoch 433/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4099 - accuracy: 0.7496 - auc: 0.8493 - precision: 0.7490 - recall: 0.7514 - val_loss: 0.4859 - val_accuracy: 0.7399 - val_auc: 0.8338 - val_precision: 0.7428 - val_recall: 0.7340\n",
            "Epoch 434/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4100 - accuracy: 0.7500 - auc: 0.8491 - precision: 0.7495 - recall: 0.7513 - val_loss: 0.4862 - val_accuracy: 0.7389 - val_auc: 0.8339 - val_precision: 0.7389 - val_recall: 0.7388\n",
            "Epoch 435/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4109 - accuracy: 0.7499 - auc: 0.8487 - precision: 0.7490 - recall: 0.7522 - val_loss: 0.4866 - val_accuracy: 0.7389 - val_auc: 0.8336 - val_precision: 0.7370 - val_recall: 0.7426\n",
            "Epoch 436/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4105 - accuracy: 0.7509 - auc: 0.8492 - precision: 0.7503 - recall: 0.7526 - val_loss: 0.4856 - val_accuracy: 0.7388 - val_auc: 0.8339 - val_precision: 0.7358 - val_recall: 0.7448\n",
            "Epoch 437/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4110 - accuracy: 0.7497 - auc: 0.8488 - precision: 0.7482 - recall: 0.7534 - val_loss: 0.4854 - val_accuracy: 0.7389 - val_auc: 0.8339 - val_precision: 0.7370 - val_recall: 0.7429\n",
            "Epoch 438/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4102 - accuracy: 0.7512 - auc: 0.8495 - precision: 0.7506 - recall: 0.7528 - val_loss: 0.4868 - val_accuracy: 0.7388 - val_auc: 0.8335 - val_precision: 0.7384 - val_recall: 0.7397\n",
            "Epoch 439/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4101 - accuracy: 0.7504 - auc: 0.8491 - precision: 0.7499 - recall: 0.7520 - val_loss: 0.4860 - val_accuracy: 0.7388 - val_auc: 0.8334 - val_precision: 0.7391 - val_recall: 0.7381\n",
            "Epoch 440/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4109 - accuracy: 0.7502 - auc: 0.8488 - precision: 0.7511 - recall: 0.7489 - val_loss: 0.4867 - val_accuracy: 0.7394 - val_auc: 0.8336 - val_precision: 0.7403 - val_recall: 0.7372\n",
            "Epoch 441/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4107 - accuracy: 0.7499 - auc: 0.8488 - precision: 0.7484 - recall: 0.7533 - val_loss: 0.4871 - val_accuracy: 0.7385 - val_auc: 0.8338 - val_precision: 0.7349 - val_recall: 0.7462\n",
            "Epoch 442/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4093 - accuracy: 0.7495 - auc: 0.8498 - precision: 0.7469 - recall: 0.7553 - val_loss: 0.4856 - val_accuracy: 0.7393 - val_auc: 0.8336 - val_precision: 0.7418 - val_recall: 0.7340\n",
            "Epoch 443/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4099 - accuracy: 0.7495 - auc: 0.8491 - precision: 0.7493 - recall: 0.7503 - val_loss: 0.4863 - val_accuracy: 0.7381 - val_auc: 0.8342 - val_precision: 0.7351 - val_recall: 0.7443\n",
            "Epoch 444/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4099 - accuracy: 0.7513 - auc: 0.8496 - precision: 0.7506 - recall: 0.7532 - val_loss: 0.4864 - val_accuracy: 0.7393 - val_auc: 0.8340 - val_precision: 0.7415 - val_recall: 0.7345\n",
            "Epoch 445/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4103 - accuracy: 0.7508 - auc: 0.8493 - precision: 0.7521 - recall: 0.7488 - val_loss: 0.4883 - val_accuracy: 0.7392 - val_auc: 0.8338 - val_precision: 0.7387 - val_recall: 0.7401\n",
            "Epoch 446/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4103 - accuracy: 0.7502 - auc: 0.8490 - precision: 0.7511 - recall: 0.7491 - val_loss: 0.4869 - val_accuracy: 0.7392 - val_auc: 0.8338 - val_precision: 0.7391 - val_recall: 0.7392\n",
            "Epoch 447/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4104 - accuracy: 0.7504 - auc: 0.8491 - precision: 0.7495 - recall: 0.7528 - val_loss: 0.4862 - val_accuracy: 0.7383 - val_auc: 0.8341 - val_precision: 0.7348 - val_recall: 0.7456\n",
            "Epoch 448/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4108 - accuracy: 0.7509 - auc: 0.8489 - precision: 0.7519 - recall: 0.7494 - val_loss: 0.4860 - val_accuracy: 0.7395 - val_auc: 0.8341 - val_precision: 0.7365 - val_recall: 0.7455\n",
            "Epoch 449/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4094 - accuracy: 0.7517 - auc: 0.8500 - precision: 0.7499 - recall: 0.7558 - val_loss: 0.4866 - val_accuracy: 0.7398 - val_auc: 0.8340 - val_precision: 0.7385 - val_recall: 0.7424\n",
            "Epoch 450/500\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.4107 - accuracy: 0.7500 - auc: 0.8488 - precision: 0.7471 - recall: 0.7564 - val_loss: 0.4863 - val_accuracy: 0.7389 - val_auc: 0.8337 - val_precision: 0.7403 - val_recall: 0.7358\n",
            "Epoch 451/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4098 - accuracy: 0.7503 - auc: 0.8493 - precision: 0.7491 - recall: 0.7533 - val_loss: 0.4860 - val_accuracy: 0.7390 - val_auc: 0.8339 - val_precision: 0.7394 - val_recall: 0.7381\n",
            "Epoch 452/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4103 - accuracy: 0.7509 - auc: 0.8490 - precision: 0.7500 - recall: 0.7533 - val_loss: 0.4867 - val_accuracy: 0.7406 - val_auc: 0.8335 - val_precision: 0.7475 - val_recall: 0.7267\n",
            "Epoch 453/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4100 - accuracy: 0.7507 - auc: 0.8488 - precision: 0.7555 - recall: 0.7417 - val_loss: 0.4867 - val_accuracy: 0.7404 - val_auc: 0.8335 - val_precision: 0.7419 - val_recall: 0.7372\n",
            "Epoch 454/500\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.4098 - accuracy: 0.7511 - auc: 0.8494 - precision: 0.7530 - recall: 0.7478 - val_loss: 0.4852 - val_accuracy: 0.7401 - val_auc: 0.8342 - val_precision: 0.7403 - val_recall: 0.7395\n",
            "Epoch 455/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4096 - accuracy: 0.7514 - auc: 0.8496 - precision: 0.7527 - recall: 0.7494 - val_loss: 0.4867 - val_accuracy: 0.7409 - val_auc: 0.8340 - val_precision: 0.7442 - val_recall: 0.7339\n",
            "Epoch 456/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4099 - accuracy: 0.7510 - auc: 0.8497 - precision: 0.7512 - recall: 0.7510 - val_loss: 0.4873 - val_accuracy: 0.7402 - val_auc: 0.8342 - val_precision: 0.7408 - val_recall: 0.7388\n",
            "Epoch 457/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4103 - accuracy: 0.7514 - auc: 0.8495 - precision: 0.7534 - recall: 0.7480 - val_loss: 0.4857 - val_accuracy: 0.7426 - val_auc: 0.8341 - val_precision: 0.7576 - val_recall: 0.7135\n",
            "Epoch 458/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4096 - accuracy: 0.7510 - auc: 0.8497 - precision: 0.7554 - recall: 0.7428 - val_loss: 0.4861 - val_accuracy: 0.7424 - val_auc: 0.8341 - val_precision: 0.7536 - val_recall: 0.7203\n",
            "Epoch 459/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4101 - accuracy: 0.7514 - auc: 0.8494 - precision: 0.7565 - recall: 0.7419 - val_loss: 0.4857 - val_accuracy: 0.7419 - val_auc: 0.8341 - val_precision: 0.7521 - val_recall: 0.7216\n",
            "Epoch 460/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4095 - accuracy: 0.7508 - auc: 0.8502 - precision: 0.7527 - recall: 0.7474 - val_loss: 0.4861 - val_accuracy: 0.7408 - val_auc: 0.8341 - val_precision: 0.7415 - val_recall: 0.7391\n",
            "Epoch 461/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4102 - accuracy: 0.7507 - auc: 0.8494 - precision: 0.7535 - recall: 0.7455 - val_loss: 0.4861 - val_accuracy: 0.7404 - val_auc: 0.8341 - val_precision: 0.7424 - val_recall: 0.7361\n",
            "Epoch 462/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4100 - accuracy: 0.7509 - auc: 0.8497 - precision: 0.7510 - recall: 0.7513 - val_loss: 0.4867 - val_accuracy: 0.7408 - val_auc: 0.8340 - val_precision: 0.7442 - val_recall: 0.7339\n",
            "Epoch 463/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4094 - accuracy: 0.7502 - auc: 0.8500 - precision: 0.7500 - recall: 0.7510 - val_loss: 0.4879 - val_accuracy: 0.7392 - val_auc: 0.8338 - val_precision: 0.7357 - val_recall: 0.7463\n",
            "Epoch 464/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4095 - accuracy: 0.7505 - auc: 0.8494 - precision: 0.7496 - recall: 0.7529 - val_loss: 0.4888 - val_accuracy: 0.7378 - val_auc: 0.8336 - val_precision: 0.7320 - val_recall: 0.7502\n",
            "Epoch 465/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4104 - accuracy: 0.7494 - auc: 0.8489 - precision: 0.7474 - recall: 0.7540 - val_loss: 0.4871 - val_accuracy: 0.7400 - val_auc: 0.8335 - val_precision: 0.7391 - val_recall: 0.7417\n",
            "Epoch 466/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4086 - accuracy: 0.7510 - auc: 0.8505 - precision: 0.7504 - recall: 0.7529 - val_loss: 0.4872 - val_accuracy: 0.7378 - val_auc: 0.8339 - val_precision: 0.7333 - val_recall: 0.7471\n",
            "Epoch 467/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4103 - accuracy: 0.7494 - auc: 0.8490 - precision: 0.7470 - recall: 0.7546 - val_loss: 0.4865 - val_accuracy: 0.7380 - val_auc: 0.8343 - val_precision: 0.7314 - val_recall: 0.7521\n",
            "Epoch 468/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4103 - accuracy: 0.7496 - auc: 0.8491 - precision: 0.7451 - recall: 0.7592 - val_loss: 0.4864 - val_accuracy: 0.7392 - val_auc: 0.8339 - val_precision: 0.7397 - val_recall: 0.7382\n",
            "Epoch 469/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4101 - accuracy: 0.7507 - auc: 0.8495 - precision: 0.7486 - recall: 0.7555 - val_loss: 0.4868 - val_accuracy: 0.7390 - val_auc: 0.8340 - val_precision: 0.7378 - val_recall: 0.7415\n",
            "Epoch 470/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4104 - accuracy: 0.7500 - auc: 0.8490 - precision: 0.7469 - recall: 0.7570 - val_loss: 0.4858 - val_accuracy: 0.7387 - val_auc: 0.8341 - val_precision: 0.7388 - val_recall: 0.7384\n",
            "Epoch 471/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4091 - accuracy: 0.7511 - auc: 0.8501 - precision: 0.7498 - recall: 0.7540 - val_loss: 0.4865 - val_accuracy: 0.7398 - val_auc: 0.8342 - val_precision: 0.7386 - val_recall: 0.7421\n",
            "Epoch 472/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4102 - accuracy: 0.7498 - auc: 0.8492 - precision: 0.7482 - recall: 0.7536 - val_loss: 0.4868 - val_accuracy: 0.7382 - val_auc: 0.8336 - val_precision: 0.7332 - val_recall: 0.7489\n",
            "Epoch 473/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4100 - accuracy: 0.7511 - auc: 0.8499 - precision: 0.7479 - recall: 0.7580 - val_loss: 0.4854 - val_accuracy: 0.7394 - val_auc: 0.8337 - val_precision: 0.7380 - val_recall: 0.7421\n",
            "Epoch 474/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4099 - accuracy: 0.7503 - auc: 0.8492 - precision: 0.7470 - recall: 0.7575 - val_loss: 0.4862 - val_accuracy: 0.7389 - val_auc: 0.8336 - val_precision: 0.7393 - val_recall: 0.7381\n",
            "Epoch 475/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4092 - accuracy: 0.7501 - auc: 0.8502 - precision: 0.7481 - recall: 0.7545 - val_loss: 0.4879 - val_accuracy: 0.7386 - val_auc: 0.8335 - val_precision: 0.7351 - val_recall: 0.7457\n",
            "Epoch 476/500\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.4094 - accuracy: 0.7519 - auc: 0.8499 - precision: 0.7537 - recall: 0.7489 - val_loss: 0.4864 - val_accuracy: 0.7403 - val_auc: 0.8342 - val_precision: 0.7434 - val_recall: 0.7339\n",
            "Epoch 477/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4104 - accuracy: 0.7504 - auc: 0.8493 - precision: 0.7511 - recall: 0.7496 - val_loss: 0.4850 - val_accuracy: 0.7399 - val_auc: 0.8337 - val_precision: 0.7433 - val_recall: 0.7327\n",
            "Epoch 478/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4096 - accuracy: 0.7496 - auc: 0.8494 - precision: 0.7486 - recall: 0.7522 - val_loss: 0.4862 - val_accuracy: 0.7393 - val_auc: 0.8337 - val_precision: 0.7413 - val_recall: 0.7349\n",
            "Epoch 479/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4102 - accuracy: 0.7511 - auc: 0.8493 - precision: 0.7500 - recall: 0.7537 - val_loss: 0.4865 - val_accuracy: 0.7401 - val_auc: 0.8341 - val_precision: 0.7392 - val_recall: 0.7419\n",
            "Epoch 480/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4107 - accuracy: 0.7503 - auc: 0.8491 - precision: 0.7485 - recall: 0.7545 - val_loss: 0.4864 - val_accuracy: 0.7392 - val_auc: 0.8338 - val_precision: 0.7418 - val_recall: 0.7336\n",
            "Epoch 481/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4090 - accuracy: 0.7518 - auc: 0.8501 - precision: 0.7510 - recall: 0.7539 - val_loss: 0.4866 - val_accuracy: 0.7396 - val_auc: 0.8341 - val_precision: 0.7403 - val_recall: 0.7381\n",
            "Epoch 482/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4084 - accuracy: 0.7533 - auc: 0.8509 - precision: 0.7572 - recall: 0.7460 - val_loss: 0.4868 - val_accuracy: 0.7389 - val_auc: 0.8337 - val_precision: 0.7372 - val_recall: 0.7424\n",
            "Epoch 483/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4091 - accuracy: 0.7501 - auc: 0.8499 - precision: 0.7479 - recall: 0.7549 - val_loss: 0.4868 - val_accuracy: 0.7389 - val_auc: 0.8336 - val_precision: 0.7384 - val_recall: 0.7399\n",
            "Epoch 484/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4102 - accuracy: 0.7504 - auc: 0.8489 - precision: 0.7484 - recall: 0.7549 - val_loss: 0.4861 - val_accuracy: 0.7383 - val_auc: 0.8337 - val_precision: 0.7394 - val_recall: 0.7360\n",
            "Epoch 485/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4098 - accuracy: 0.7505 - auc: 0.8493 - precision: 0.7507 - recall: 0.7505 - val_loss: 0.4871 - val_accuracy: 0.7398 - val_auc: 0.8339 - val_precision: 0.7433 - val_recall: 0.7325\n",
            "Epoch 486/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4100 - accuracy: 0.7498 - auc: 0.8497 - precision: 0.7480 - recall: 0.7541 - val_loss: 0.4882 - val_accuracy: 0.7401 - val_auc: 0.8338 - val_precision: 0.7400 - val_recall: 0.7402\n",
            "Epoch 487/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4095 - accuracy: 0.7503 - auc: 0.8494 - precision: 0.7484 - recall: 0.7545 - val_loss: 0.4867 - val_accuracy: 0.7387 - val_auc: 0.8337 - val_precision: 0.7370 - val_recall: 0.7422\n",
            "Epoch 488/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4100 - accuracy: 0.7511 - auc: 0.8494 - precision: 0.7505 - recall: 0.7528 - val_loss: 0.4862 - val_accuracy: 0.7403 - val_auc: 0.8338 - val_precision: 0.7441 - val_recall: 0.7324\n",
            "Epoch 489/500\n",
            "205/205 [==============================] - 3s 17ms/step - loss: 0.4103 - accuracy: 0.7505 - auc: 0.8490 - precision: 0.7519 - recall: 0.7483 - val_loss: 0.4846 - val_accuracy: 0.7396 - val_auc: 0.8344 - val_precision: 0.7389 - val_recall: 0.7409\n",
            "Epoch 490/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4090 - accuracy: 0.7506 - auc: 0.8503 - precision: 0.7490 - recall: 0.7545 - val_loss: 0.4864 - val_accuracy: 0.7395 - val_auc: 0.8339 - val_precision: 0.7408 - val_recall: 0.7368\n",
            "Epoch 491/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4099 - accuracy: 0.7503 - auc: 0.8493 - precision: 0.7496 - recall: 0.7522 - val_loss: 0.4870 - val_accuracy: 0.7391 - val_auc: 0.8339 - val_precision: 0.7400 - val_recall: 0.7372\n",
            "Epoch 492/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4090 - accuracy: 0.7503 - auc: 0.8499 - precision: 0.7485 - recall: 0.7546 - val_loss: 0.4884 - val_accuracy: 0.7389 - val_auc: 0.8336 - val_precision: 0.7398 - val_recall: 0.7370\n",
            "Epoch 493/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4095 - accuracy: 0.7503 - auc: 0.8497 - precision: 0.7518 - recall: 0.7479 - val_loss: 0.4860 - val_accuracy: 0.7387 - val_auc: 0.8343 - val_precision: 0.7389 - val_recall: 0.7381\n",
            "Epoch 494/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4096 - accuracy: 0.7514 - auc: 0.8499 - precision: 0.7538 - recall: 0.7473 - val_loss: 0.4855 - val_accuracy: 0.7393 - val_auc: 0.8341 - val_precision: 0.7409 - val_recall: 0.7359\n",
            "Epoch 495/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4102 - accuracy: 0.7500 - auc: 0.8494 - precision: 0.7519 - recall: 0.7467 - val_loss: 0.4862 - val_accuracy: 0.7387 - val_auc: 0.8340 - val_precision: 0.7386 - val_recall: 0.7388\n",
            "Epoch 496/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4101 - accuracy: 0.7500 - auc: 0.8492 - precision: 0.7504 - recall: 0.7496 - val_loss: 0.4863 - val_accuracy: 0.7391 - val_auc: 0.8341 - val_precision: 0.7399 - val_recall: 0.7372\n",
            "Epoch 497/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4092 - accuracy: 0.7520 - auc: 0.8503 - precision: 0.7531 - recall: 0.7503 - val_loss: 0.4872 - val_accuracy: 0.7396 - val_auc: 0.8341 - val_precision: 0.7423 - val_recall: 0.7338\n",
            "Epoch 498/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4098 - accuracy: 0.7533 - auc: 0.8498 - precision: 0.7597 - recall: 0.7413 - val_loss: 0.4866 - val_accuracy: 0.7410 - val_auc: 0.8341 - val_precision: 0.7524 - val_recall: 0.7185\n",
            "Epoch 499/500\n",
            "205/205 [==============================] - 3s 15ms/step - loss: 0.4094 - accuracy: 0.7526 - auc: 0.8496 - precision: 0.7605 - recall: 0.7380 - val_loss: 0.4860 - val_accuracy: 0.7405 - val_auc: 0.8339 - val_precision: 0.7541 - val_recall: 0.7138\n",
            "Epoch 500/500\n",
            "205/205 [==============================] - 3s 16ms/step - loss: 0.4095 - accuracy: 0.7516 - auc: 0.8494 - precision: 0.7590 - recall: 0.7380 - val_loss: 0.4864 - val_accuracy: 0.7403 - val_auc: 0.8344 - val_precision: 0.7423 - val_recall: 0.7361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRo_codARMjn",
        "outputId": "2f3160d3-d446-46f0-ea3a-8f6c56de0c62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('training evaluation:')\n",
        "eval_train = model.evaluate(train_data)\n",
        "print('\\nvalidation evaluation:') \n",
        "eval_val = model.evaluate(val_data)\n",
        "print('\\ntest evaluation:')\n",
        "eval_test = model.evaluate(test_data)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training evaluation:\n",
            "205/205 [==============================] - 2s 9ms/step - loss: 0.4414 - accuracy: 0.7602 - auc: 0.8601 - precision: 0.7599 - recall: 0.7614\n",
            "\n",
            "validation evaluation:\n",
            "69/69 [==============================] - 1s 9ms/step - loss: 0.4864 - accuracy: 0.7403 - auc: 0.8344 - precision: 0.7423 - recall: 0.7361\n",
            "\n",
            "test evaluation:\n",
            "69/69 [==============================] - 1s 9ms/step - loss: 0.5026 - accuracy: 0.7323 - auc: 0.8278 - precision: 0.7320 - recall: 0.7313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fkCdIQuqRxt",
        "outputId": "674aba67-3764-40ed-acd1-aa1dcccc79b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.save('drive/My Drive/ffn/model.tfm')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'created_date': <tf.Tensor 'created_date:0' shape=(None, 1) dtype=string>, 'location_in_query': <tf.Tensor 'location_in_query:0' shape=(None, 1) dtype=string>, 'platform': <tf.Tensor 'platform:0' shape=(None, 1) dtype=string>, 'campaign_state': <tf.Tensor 'campaign_state:0' shape=(None, 1) dtype=string>, 'in_city': <tf.Tensor 'in_city:0' shape=(None, 1) dtype=int64>, 'is_prime': <tf.Tensor 'is_prime:0' shape=(None, 1) dtype=int64>, 'is_hardship': <tf.Tensor 'is_hardship:0' shape=(None, 1) dtype=int64>, 'category_debt_type': <tf.Tensor 'category_debt_type:0' shape=(None, 1) dtype=string>, 'time_index': <tf.Tensor 'time_index:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'created_date': <tf.Tensor 'created_date:0' shape=(None, 1) dtype=string>, 'location_in_query': <tf.Tensor 'location_in_query:0' shape=(None, 1) dtype=string>, 'platform': <tf.Tensor 'platform:0' shape=(None, 1) dtype=string>, 'campaign_state': <tf.Tensor 'campaign_state:0' shape=(None, 1) dtype=string>, 'in_city': <tf.Tensor 'in_city:0' shape=(None, 1) dtype=int64>, 'is_prime': <tf.Tensor 'is_prime:0' shape=(None, 1) dtype=int64>, 'is_hardship': <tf.Tensor 'is_hardship:0' shape=(None, 1) dtype=int64>, 'category_debt_type': <tf.Tensor 'category_debt_type:0' shape=(None, 1) dtype=string>, 'time_index': <tf.Tensor 'time_index:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'created_date': <tf.Tensor 'created_date:0' shape=(None, 1) dtype=string>, 'location_in_query': <tf.Tensor 'location_in_query:0' shape=(None, 1) dtype=string>, 'platform': <tf.Tensor 'platform:0' shape=(None, 1) dtype=string>, 'campaign_state': <tf.Tensor 'campaign_state:0' shape=(None, 1) dtype=string>, 'in_city': <tf.Tensor 'in_city:0' shape=(None, 1) dtype=int64>, 'is_prime': <tf.Tensor 'is_prime:0' shape=(None, 1) dtype=int64>, 'is_hardship': <tf.Tensor 'is_hardship:0' shape=(None, 1) dtype=int64>, 'category_debt_type': <tf.Tensor 'category_debt_type:0' shape=(None, 1) dtype=string>, 'time_index': <tf.Tensor 'time_index:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'created_date': <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=string>, 'location_in_query': <tf.Tensor 'inputs_6:0' shape=(None, 1) dtype=string>, 'platform': <tf.Tensor 'inputs_7:0' shape=(None, 1) dtype=string>, 'campaign_state': <tf.Tensor 'inputs:0' shape=(None, 1) dtype=string>, 'in_city': <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=int64>, 'is_prime': <tf.Tensor 'inputs_5:0' shape=(None, 1) dtype=int64>, 'is_hardship': <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=int64>, 'category_debt_type': <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=string>, 'time_index': <tf.Tensor 'inputs_8:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'created_date': <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=string>, 'location_in_query': <tf.Tensor 'inputs_6:0' shape=(None, 1) dtype=string>, 'platform': <tf.Tensor 'inputs_7:0' shape=(None, 1) dtype=string>, 'campaign_state': <tf.Tensor 'inputs:0' shape=(None, 1) dtype=string>, 'in_city': <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=int64>, 'is_prime': <tf.Tensor 'inputs_5:0' shape=(None, 1) dtype=int64>, 'is_hardship': <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=int64>, 'category_debt_type': <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=string>, 'time_index': <tf.Tensor 'inputs_8:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'created_date': <tf.Tensor 'inputs/created_date:0' shape=(None, 1) dtype=string>, 'location_in_query': <tf.Tensor 'inputs/location_in_query:0' shape=(None, 1) dtype=string>, 'platform': <tf.Tensor 'inputs/platform:0' shape=(None, 1) dtype=string>, 'campaign_state': <tf.Tensor 'inputs/campaign_state:0' shape=(None, 1) dtype=string>, 'in_city': <tf.Tensor 'inputs/in_city:0' shape=(None, 1) dtype=int64>, 'is_prime': <tf.Tensor 'inputs/is_prime:0' shape=(None, 1) dtype=int64>, 'is_hardship': <tf.Tensor 'inputs/is_hardship:0' shape=(None, 1) dtype=int64>, 'category_debt_type': <tf.Tensor 'inputs/category_debt_type:0' shape=(None, 1) dtype=string>, 'time_index': <tf.Tensor 'inputs/time_index:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'created_date': <tf.Tensor 'inputs/created_date:0' shape=(None, 1) dtype=string>, 'location_in_query': <tf.Tensor 'inputs/location_in_query:0' shape=(None, 1) dtype=string>, 'platform': <tf.Tensor 'inputs/platform:0' shape=(None, 1) dtype=string>, 'campaign_state': <tf.Tensor 'inputs/campaign_state:0' shape=(None, 1) dtype=string>, 'in_city': <tf.Tensor 'inputs/in_city:0' shape=(None, 1) dtype=int64>, 'is_prime': <tf.Tensor 'inputs/is_prime:0' shape=(None, 1) dtype=int64>, 'is_hardship': <tf.Tensor 'inputs/is_hardship:0' shape=(None, 1) dtype=int64>, 'category_debt_type': <tf.Tensor 'inputs/category_debt_type:0' shape=(None, 1) dtype=string>, 'time_index': <tf.Tensor 'inputs/time_index:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/ffn/model.tfm/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SBYG3Hv-cYp"
      },
      "source": [
        "## Model performance evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssWPNe7O9fdB",
        "outputId": "d5103a81-313f-49d6-c645-cbc61dff691a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        }
      },
      "source": [
        "# load plotting modules\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# setting fonts for axes\n",
        "matplotlib.rcParams['figure.figsize'] = [24, 12] # width and height of figures\n",
        "\n",
        "font = {'family' : 'DejaVu Sans', # font\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 16}\n",
        "matplotlib.rc('font', **font)\n",
        "\n",
        "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "\n",
        "for n, metric in enumerate(metrics_names[0:5]):\n",
        "    name = metric.replace(\"_\",\" \").upper()\n",
        "    plt.subplot(2,3,n+1)\n",
        "    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='train')\n",
        "    plt.plot(history.epoch, history.history['val_'+metric], color=colors[1], linestyle=\"-\", label='valid')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel(name)\n",
        "    plt.ylim([0,1])\n",
        "    if metric == 'auc': plt.legend()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1728x864 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blw6aGyXxPLF",
        "outputId": "87c2949d-6028-4c16-a24f-ec98eece066a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "end_time = datetime.datetime.now()\n",
        "print('total run time:', end_time - start_time)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total run time: 0:28:16.290848\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}